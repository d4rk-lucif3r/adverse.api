{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adverse_media.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMZ/sbQukfuY97UwXtwDgjN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QaOldEw1CHg1"},"source":["Step #1:\r\n","---\r\n","* Clone the repo\r\n","* Install the dependencies"]},{"cell_type":"code","metadata":{"id":"9q7dt-AJC0VU"},"source":["!git clone https://gauravchopragc:07Aug1998!@bitbucket.org/IntelleWing/pep.api.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4qSliicC7MI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1614366160795,"user_tz":-330,"elapsed":106362,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"529b85c4-a7df-4dd5-81c2-35cfe2ee9aa6"},"source":["%cd /content/pep.api\r\n","!pip install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/pep.api\n","Requirement already satisfied: absl-py==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.10.0)\n","Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.8.1)\n","Collecting attrs==20.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/df/479736ae1ef59842f512548bacefad1abed705e400212acba43f9b0fa556/attrs-20.2.0-py2.py3-none-any.whl (48kB)\n","\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n","\u001b[?25hCollecting Automat==20.2.0\n","  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.9.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/25/ff030e2437265616a1e9b25ccc864e0371a0bc3adb7c5a404fd661c6f4f6/beautifulsoup4-4.9.1-py3-none-any.whl (115kB)\n","\u001b[K     |████████████████████████████████| 122kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: blis==0.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.4.1)\n","Requirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.0.1)\n","Collecting cachetools==4.1.1\n","  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n","Collecting certifi==2020.6.20\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\n","\u001b[K     |████████████████████████████████| 163kB 7.1MB/s \n","\u001b[?25hCollecting cffi==1.14.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/82/cc3e38b7859e1426d7c004503962074317f3ccbd46adbef5b8094c9688c3/cffi-1.14.2-cp37-cp37m-manylinux1_x86_64.whl (401kB)\n","\u001b[K     |████████████████████████████████| 409kB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (3.0.4)\n","Collecting constantly==15.1.0\n","  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n","Collecting cryptography==3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/9c/647e559a6e8be493dc2a7a5d15d26cb501ca60ec299b356f23839a673a83/cryptography-3.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 11.6MB/s \n","\u001b[?25hCollecting cssselect==1.1.0\n","  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n","Collecting cymem==2.0.3\n","  Downloading https://files.pythonhosted.org/packages/e1/79/6ce05ecf4d50344e29749ea7db7ddf427589228fb8fe89b29718c38c27c5/cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl\n","Collecting fake-headers==1.0.2\n","  Downloading https://files.pythonhosted.org/packages/35/1c/cfdc7cab0058e43a9b12f5cae6ae4e1318228b3de1604798de8c4b0ea94b/fake_headers-1.0.2-py3-none-any.whl\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting google-auth==1.21.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/22/f241c17eeafb8b8fcb75a13e3e438a78a0c14768936fe81800d477514afe/google_auth-1.21.2-py2.py3-none-any.whl (93kB)\n","\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n","\u001b[?25hCollecting google-auth-oauthlib==0.4.1\n","  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n","Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.2.0)\n","Collecting googletrans==3.0.0\n","  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n","Requirement already satisfied: grpcio==1.32.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (1.32.0)\n","Collecting h11==0.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n","\u001b[?25hCollecting h2==3.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 25)) (2.10.0)\n","Collecting hpack==3.0.0\n","  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n","Collecting hstspreload==2020.11.21\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/3c/cdeaf9ab0404853e77c45d9e8021d0d2c01f70a1bb26e460090926fe2a5e/hstspreload-2020.11.21-py3-none-any.whl (981kB)\n","\u001b[K     |████████████████████████████████| 983kB 30.9MB/s \n","\u001b[?25hCollecting html5lib==1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 42.9MB/s \n","\u001b[?25hCollecting httpcore==0.9.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n","\u001b[?25hCollecting httpx==0.13.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n","\u001b[?25hCollecting hyperframe==5.2.0\n","  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n","Collecting hyperlink==20.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/a5/74f77547e9b175eb894d4fec5c76b0c8176c045e5bf3ac6a4d4d3feab4bb/hyperlink-20.0.1-py2.py3-none-any.whl (48kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (2.10)\n","Collecting importlib-metadata==1.7.0\n","  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n","Collecting incremental==17.5.0\n","  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n","Collecting itemadapter==0.1.0\n","  Downloading https://files.pythonhosted.org/packages/7d/fb/92f848fcfa85dc9f95370eaecb5c99b5230dd4fc5c6bae684f4ca59df973/itemadapter-0.1.0-py3-none-any.whl\n","Collecting itemloaders==1.0.3\n","  Downloading https://files.pythonhosted.org/packages/b9/c5/bd4d083c6d5368885cb8d10ea8355d38a958a57e5bc73945fc3905a7e1ca/itemloaders-1.0.3-py3-none-any.whl\n","Collecting jmespath==0.10.0\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting Keras==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n","\u001b[K     |████████████████████████████████| 378kB 43.2MB/s \n","\u001b[?25hCollecting Keras-Applications==1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n","\u001b[?25hRequirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (1.1.2)\n","Collecting lxml==4.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/3c/fa420469c0d4f62ae39f19ee6505f90d00ae469f6264f4f54e61ed9d9a2c/lxml-4.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n","\u001b[K     |████████████████████████████████| 5.5MB 36.6MB/s \n","\u001b[?25hCollecting Markdown==3.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.9MB/s \n","\u001b[?25hCollecting murmurhash==1.0.2\n","  Downloading https://files.pythonhosted.org/packages/73/fc/10eeacb926ec1e88cd62f79d9ac106b0a3e3fe5ff1690422d88c29bd0909/murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl\n","Collecting numpy==1.19.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/04/c3846024ddc7514cde17087f62f0502abf85c53e8f69f6312c70db6d144e/numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n","\u001b[K     |████████████████████████████████| 14.5MB 309kB/s \n","\u001b[?25hRequirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 46)) (3.1.0)\n","Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 47)) (3.3.0)\n","Collecting pandas==1.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/69/18b96b520519818e00b04dd08d7cbc5e764f1465f5a280cf96173f34c54e/pandas-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (10.5MB)\n","\u001b[K     |████████████████████████████████| 10.5MB 41.8MB/s \n","\u001b[?25hCollecting parsel==1.6.0\n","  Downloading https://files.pythonhosted.org/packages/23/1e/9b39d64cbab79d4362cdd7be7f5e9623d45c4a53b3f7522cd8210df52d8e/parsel-1.6.0-py2.py3-none-any.whl\n","Collecting plac==0.9.6\n","  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n","Collecting preshed==3.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/5b/ae4da6230eb48df353b199f53532c8407d0e9eb6ed678d3d36fa75ac391c/preshed-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (118kB)\n","\u001b[K     |████████████████████████████████| 122kB 49.3MB/s \n","\u001b[?25hCollecting Protego==0.1.16\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6e/bf6d5e4d7cf233b785719aaec2c38f027b9c2ed980a0015ec1a1cced4893/Protego-0.1.16.tar.gz (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 48.5MB/s \n","\u001b[?25hCollecting protobuf==3.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/dc/5ba56eab7440c62c5f808b4267e2a1d6c136e90293b43fefb1b493c6d704/protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 47.5MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 54)) (0.4.8)\n","Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 55)) (0.2.8)\n","Requirement already satisfied: pycparser==2.20 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 56)) (2.20)\n","Collecting PyDispatcher==2.0.5\n","  Downloading https://files.pythonhosted.org/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz\n","Collecting PyHamcrest==2.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/16/e54cc65891f01cb62893540f44ffd3e8dab0a22443e1b438f1a9f5574bee/PyHamcrest-2.0.2-py3-none-any.whl (52kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n","\u001b[?25hCollecting pyOpenSSL==19.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 60)) (2.8.1)\n","Collecting pytz==2020.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/a4/879454d49688e2fad93e59d7d4efda580b783c745fd2ec2a3adf87b0808d/pytz-2020.1-py2.py3-none-any.whl (510kB)\n","\u001b[K     |████████████████████████████████| 512kB 37.8MB/s \n","\u001b[?25hCollecting PyYAML==5.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 55.4MB/s \n","\u001b[?25hCollecting queuelib==1.5.0\n","  Downloading https://files.pythonhosted.org/packages/4c/85/ae64e9145f39dd6d14f8af3fa809a270ef3729f3b90b3c0cf5aa242ab0d4/queuelib-1.5.0-py2.py3-none-any.whl\n","Collecting requests==2.24.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 65)) (1.3.0)\n","Collecting rfc3986==1.4.0\n","  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n","Collecting rsa==4.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n","\u001b[?25hCollecting scipy==1.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/f9/f7a7e5009711579c72da2725174825e5056741bf4001815d097eef1b2e17/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n","\u001b[K     |████████████████████████████████| 25.9MB 907kB/s \n","\u001b[?25hCollecting Scrapy==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/59/a942878de3fb03481207a32bea488d7c3bd6bd8deecdbf90b6746dfa2da0/Scrapy-2.3.0-py2.py3-none-any.whl (237kB)\n","\u001b[K     |████████████████████████████████| 245kB 55.6MB/s \n","\u001b[?25hCollecting service-identity==18.1.0\n","  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n","Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 71)) (1.15.0)\n","Collecting sniffio==1.2.0\n","  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n","Collecting soupsieve==2.0.1\n","  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\n","Collecting spacy==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/ed/6f1281a10c4fe64ae8b1a5dc9ab60e7f1a09480367e1d9e2c874d5850356/spacy-2.2.0-cp37-cp37m-manylinux1_x86_64.whl (10.2MB)\n","\u001b[K     |████████████████████████████████| 10.2MB 21.1MB/s \n","\u001b[?25hCollecting srsly==1.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/27/0e1deb477dd422427a18d8283b7aacf48b5f77c668feeb2c4920ee6cc3a3/srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185kB)\n","\u001b[K     |████████████████████████████████| 194kB 46.4MB/s \n","\u001b[?25hCollecting tensorboard==2.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 42.2MB/s \n","\u001b[?25hCollecting tensorflow==2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3MB)\n","\u001b[K     |████████████████████████████████| 86.3MB 64kB/s \n","\u001b[?25hCollecting tensorflow-estimator==2.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 36.1MB/s \n","\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 79)) (1.1.0)\n","Collecting thinc==7.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/57/e72a6ff850a00eab0c6fd83a5d24a24dfb712d0a1c29a428a679a2aadad5/thinc-7.1.1-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 18.2MB/s \n","\u001b[?25hCollecting tqdm==4.49.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/d5/f220e0c69b2f346b5649b66abebb391df1a00a59997a7ccf823325bd7a3e/tqdm-4.49.0-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n","\u001b[?25hCollecting Twisted==20.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/f9/489416dda6de8ae6419356bf003c10d1ce6fb8377b6a3207b02b3a39c42a/Twisted-20.3.0-cp37-cp37m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 29.1MB/s \n","\u001b[?25hCollecting Unidecode==1.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 56.4MB/s \n","\u001b[?25hCollecting urllib3==1.25.10\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 45.7MB/s \n","\u001b[?25hCollecting w3lib==1.22.0\n","  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n","Collecting wasabi==0.8.0\n","  Downloading https://files.pythonhosted.org/packages/1b/10/55f3cf6b52cc89107b3e1b88fcf39719392b377a3d78ca61da85934d0d10/wasabi-0.8.0-py3-none-any.whl\n","Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 87)) (0.5.1)\n","Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 88)) (1.0.1)\n","Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 89)) (1.12.1)\n","Collecting zipp==3.1.0\n","  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n","Collecting zope.interface==5.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/15/6f162e1fff07c6d30abfd1185ccc673057973eec2e025b490ed41125266f/zope.interface-5.1.0-cp37-cp37m-manylinux2010_x86_64.whl (235kB)\n","\u001b[K     |████████████████████████████████| 245kB 44.0MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.21.2->-r requirements.txt (line 18)) (53.0.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.0.2->-r requirements.txt (line 76)) (0.36.2)\n","Building wheels for collected packages: gast, googletrans, Protego, PyDispatcher, PyYAML\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=8a34865622152464677936576a1e92c8928e6b6feb450c008f5e585ad6e58ebd\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googletrans: filename=googletrans-3.0.0-cp37-none-any.whl size=15737 sha256=0d64a46ecf9981fac66cba105d5296312700f43b2953f1b494052f3a9b3f6c23\n","  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n","  Building wheel for Protego (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Protego: filename=Protego-0.1.16-cp37-none-any.whl size=7766 sha256=cf1112494b01dfbef10821b145d54f079a5127bc9ab52945ec449c2eb00af067\n","  Stored in directory: /root/.cache/pip/wheels/51/01/d1/4a2286a976dccd025ba679acacfe37320540df0f2283ecab12\n","  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-cp37-none-any.whl size=11517 sha256=3189b252a4df3e50ecb99715952a96ae9b7f04daa0aa6f3fecf8c4954c1b1b43\n","  Stored in directory: /root/.cache/pip/wheels/88/99/96/cfef6665f9cb1522ee6757ae5955feedf2fe25f1737f91fa7f\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=dd9206a4cf3a084fd30ff747bf6f173a8466a118f8539ca46cace54207c61da8\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built gast googletrans Protego PyDispatcher PyYAML\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: attrs, Automat, soupsieve, beautifulsoup4, cachetools, certifi, cffi, constantly, cryptography, cssselect, cymem, html5lib, fake-headers, gast, rsa, google-auth, google-auth-oauthlib, hpack, hyperframe, h2, sniffio, h11, httpcore, rfc3986, hstspreload, httpx, googletrans, hyperlink, zipp, importlib-metadata, incremental, itemadapter, jmespath, w3lib, lxml, parsel, itemloaders, numpy, scipy, PyYAML, Keras-Applications, Keras, Markdown, murmurhash, pytz, pandas, plac, preshed, Protego, protobuf, PyDispatcher, PyHamcrest, pyOpenSSL, queuelib, urllib3, requests, zope.interface, service-identity, Twisted, Scrapy, wasabi, srsly, tqdm, thinc, spacy, tensorboard, tensorflow-estimator, tensorflow, Unidecode\n","  Found existing installation: attrs 20.3.0\n","    Uninstalling attrs-20.3.0:\n","      Successfully uninstalled attrs-20.3.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","  Found existing installation: cachetools 4.2.1\n","    Uninstalling cachetools-4.2.1:\n","      Successfully uninstalled cachetools-4.2.1\n","  Found existing installation: certifi 2020.12.5\n","    Uninstalling certifi-2020.12.5:\n","      Successfully uninstalled certifi-2020.12.5\n","  Found existing installation: cffi 1.14.5\n","    Uninstalling cffi-1.14.5:\n","      Successfully uninstalled cffi-1.14.5\n","  Found existing installation: cymem 2.0.5\n","    Uninstalling cymem-2.0.5:\n","      Successfully uninstalled cymem-2.0.5\n","  Found existing installation: html5lib 1.0.1\n","    Uninstalling html5lib-1.0.1:\n","      Successfully uninstalled html5lib-1.0.1\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: rsa 4.7.2\n","    Uninstalling rsa-4.7.2:\n","      Successfully uninstalled rsa-4.7.2\n","  Found existing installation: google-auth 1.27.0\n","    Uninstalling google-auth-1.27.0:\n","      Successfully uninstalled google-auth-1.27.0\n","  Found existing installation: google-auth-oauthlib 0.4.2\n","    Uninstalling google-auth-oauthlib-0.4.2:\n","      Successfully uninstalled google-auth-oauthlib-0.4.2\n","  Found existing installation: zipp 3.4.0\n","    Uninstalling zipp-3.4.0:\n","      Successfully uninstalled zipp-3.4.0\n","  Found existing installation: importlib-metadata 3.7.0\n","    Uninstalling importlib-metadata-3.7.0:\n","      Successfully uninstalled importlib-metadata-3.7.0\n","  Found existing installation: lxml 4.2.6\n","    Uninstalling lxml-4.2.6:\n","      Successfully uninstalled lxml-4.2.6\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","  Found existing installation: Markdown 3.3.4\n","    Uninstalling Markdown-3.3.4:\n","      Successfully uninstalled Markdown-3.3.4\n","  Found existing installation: murmurhash 1.0.5\n","    Uninstalling murmurhash-1.0.5:\n","      Successfully uninstalled murmurhash-1.0.5\n","  Found existing installation: pytz 2018.9\n","    Uninstalling pytz-2018.9:\n","      Successfully uninstalled pytz-2018.9\n","  Found existing installation: pandas 1.1.5\n","    Uninstalling pandas-1.1.5:\n","      Successfully uninstalled pandas-1.1.5\n","  Found existing installation: plac 1.1.3\n","    Uninstalling plac-1.1.3:\n","      Successfully uninstalled plac-1.1.3\n","  Found existing installation: preshed 3.0.5\n","    Uninstalling preshed-3.0.5:\n","      Successfully uninstalled preshed-3.0.5\n","  Found existing installation: protobuf 3.12.4\n","    Uninstalling protobuf-3.12.4:\n","      Successfully uninstalled protobuf-3.12.4\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: wasabi 0.8.2\n","    Uninstalling wasabi-0.8.2:\n","      Successfully uninstalled wasabi-0.8.2\n","  Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed Automat-20.2.0 Keras-2.3.0 Keras-Applications-1.0.8 Markdown-3.2.2 Protego-0.1.16 PyDispatcher-2.0.5 PyHamcrest-2.0.2 PyYAML-5.3.1 Scrapy-2.3.0 Twisted-20.3.0 Unidecode-1.1.1 attrs-20.2.0 beautifulsoup4-4.9.1 cachetools-4.1.1 certifi-2020.6.20 cffi-1.14.2 constantly-15.1.0 cryptography-3.1 cssselect-1.1.0 cymem-2.0.3 fake-headers-1.0.2 gast-0.2.2 google-auth-1.21.2 google-auth-oauthlib-0.4.1 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.11.21 html5lib-1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 hyperlink-20.0.1 importlib-metadata-1.7.0 incremental-17.5.0 itemadapter-0.1.0 itemloaders-1.0.3 jmespath-0.10.0 lxml-4.5.2 murmurhash-1.0.2 numpy-1.19.2 pandas-1.1.2 parsel-1.6.0 plac-0.9.6 preshed-3.0.2 protobuf-3.13.0 pyOpenSSL-19.1.0 pytz-2020.1 queuelib-1.5.0 requests-2.24.0 rfc3986-1.4.0 rsa-4.6 scipy-1.5.2 service-identity-18.1.0 sniffio-1.2.0 soupsieve-2.0.1 spacy-2.2.0 srsly-1.0.2 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1 thinc-7.1.1 tqdm-4.49.0 urllib3-1.25.10 w3lib-1.22.0 wasabi-0.8.0 zipp-3.1.0 zope.interface-5.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cffi","google","numpy","pandas","pytz"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"S-ikXBr72b6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614366173226,"user_tz":-330,"elapsed":12603,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"2d9678e0-a905-498d-9953-2107d52e1ad7"},"source":["!pip install spacy --upgrade"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting spacy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/06/112740b1f4b549eb12becd86b6d8891267988669844dd23e00b6ca1b997c/spacy-3.0.3-cp37-cp37m-manylinux2014_x86_64.whl (12.7MB)\n","\u001b[K     |████████████████████████████████| 12.7MB 335kB/s \n","\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.3)\n","Collecting wasabi<1.1.0,>=0.8.1\n","  Downloading https://files.pythonhosted.org/packages/a6/1d/d281571b4c3b20fff183b485c6673c62878727119a849c7932651a8b5060/wasabi-0.8.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.24.0)\n","Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Collecting catalogue<2.1.0,>=2.0.1\n","  Downloading https://files.pythonhosted.org/packages/48/5c/493a2f3bb0eac17b1d48129ecfd251f0520b6c89493e9fd0522f534a9e4a/catalogue-2.0.1-py3-none-any.whl\n","Collecting pathy\n","  Downloading https://files.pythonhosted.org/packages/a2/53/97dc0197cca9357369b3b71bf300896cf2d3604fa60ffaaf5cbc277de7de/pathy-0.4.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n","Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n","Collecting pydantic<1.8.0,>=1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0a/52ae1c659fc08f13dd7c0ae07b88e4f807ad83fb9954a59b0b0a3d1a8ab6/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n","\u001b[K     |████████████████████████████████| 9.1MB 38.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.2)\n","Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.2)\n","Collecting srsly<3.0.0,>=2.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/54/76982427ceb495dd19ff982c966708c624b85e03c45bf1912feaf60c7b2d/srsly-2.4.0-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n","\u001b[K     |████████████████████████████████| 460kB 39.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.49.0)\n","Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (53.0.0)\n","Collecting spacy-legacy<3.1.0,>=3.0.0\n","  Downloading https://files.pythonhosted.org/packages/65/d5/6c58fc97f3098775e46d8202bf248752e626a8096a0ae9d76aa7c485a09c/spacy_legacy-3.0.1-py2.py3-none-any.whl\n","Collecting thinc<8.1.0,>=8.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/0b/c3ecbeabf7827ee6fbe7eac23db379573400a23832e4571161b2aa4677ad/thinc-8.0.1-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 40.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (1.7.0)\n","Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n","Collecting smart-open<4.0.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n","\u001b[K     |████████████████████████████████| 122kB 44.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (3.1.0)\n","Building wheels for collected packages: smart-open\n","  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=3294181d3a41aa20d55b81f584f63184916beeba257224fcfcc331fd82064b3b\n","  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n","Successfully built smart-open\n","Installing collected packages: typer, wasabi, catalogue, smart-open, pathy, pydantic, srsly, spacy-legacy, thinc, spacy\n","  Found existing installation: wasabi 0.8.0\n","    Uninstalling wasabi-0.8.0:\n","      Successfully uninstalled wasabi-0.8.0\n","  Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Found existing installation: smart-open 4.2.0\n","    Uninstalling smart-open-4.2.0:\n","      Successfully uninstalled smart-open-4.2.0\n","  Found existing installation: srsly 1.0.2\n","    Uninstalling srsly-1.0.2:\n","      Successfully uninstalled srsly-1.0.2\n","  Found existing installation: thinc 7.1.1\n","    Uninstalling thinc-7.1.1:\n","      Successfully uninstalled thinc-7.1.1\n","  Found existing installation: spacy 2.2.0\n","    Uninstalling spacy-2.2.0:\n","      Successfully uninstalled spacy-2.2.0\n","Successfully installed catalogue-2.0.1 pathy-0.4.0 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.3 spacy-legacy-3.0.1 srsly-2.4.0 thinc-8.0.1 typer-0.3.2 wasabi-0.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fwIQAn9m2b6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614366226884,"user_tz":-330,"elapsed":53720,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"b0d5b22b-3421-41aa-af6f-1658c7e3fbad"},"source":["!python -m spacy download en_core_web_trf"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting en-core-web-trf==3.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.0.0/en_core_web_trf-3.0.0-py3-none-any.whl (459.7MB)\n","\u001b[K     |████████████████████████████████| 459.7MB 37kB/s \n","\u001b[?25hCollecting spacy-transformers<1.1.0,>=1.0.0rc4\n","  Downloading https://files.pythonhosted.org/packages/5b/22/51e9e59ebb0d914cf162201ca76f497a2fb1730e9fcf6cf5f5de3a2fbfc0/spacy_transformers-1.0.1-py2.py3-none-any.whl\n","Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-trf==3.0.0) (3.0.3)\n","Collecting torchcontrib<0.1.0,>=0.0.2\n","  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (1.7.0)\n","Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (1.7.1+cu101)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (2.4.0)\n","Collecting spacy-alignments<1.0.0,>=0.7.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/86/1a428af2429609f5a238e96503fc4367efda4caf2b28734903dc9eb1d92c/spacy_alignments-0.7.2-cp37-cp37m-manylinux2014_x86_64.whl (977kB)\n","\u001b[K     |████████████████████████████████| 983kB 8.1MB/s \n","\u001b[?25hCollecting ftfy<6.0.0,>=5.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/06/e5c80e2e0f979628d47345efba51f7ba386fe95963b11c594209085f5a9b/ftfy-5.9.tar.gz (66kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n","\u001b[?25hCollecting transformers<4.3.0,>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 39.6MB/s \n","\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (2.0.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (20.9)\n","Requirement already satisfied: pathy in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (0.4.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (2.0.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (1.19.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (0.8.2)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (0.3.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (3.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (3.7.4.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (3.0.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (8.0.1)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (53.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (2.11.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (2.24.0)\n","Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (1.7.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (1.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (4.49.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (3.1.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (0.2.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.3.0,>=3.1.0->spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 39.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.3.0,>=3.1.0->spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 46.8MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (2.4.7)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (3.0.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (1.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (1.25.10)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-trf==3.0.0) (2020.6.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.3.0,>=3.1.0->spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.3.0,>=3.1.0->spacy-transformers<1.1.0,>=1.0.0rc4->en-core-web-trf==3.0.0) (1.0.1)\n","Building wheels for collected packages: torchcontrib, ftfy, sacremoses\n","  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-cp37-none-any.whl size=7532 sha256=957cfb90d2af4d9102e8115655629df3d3e002d4c36dacabc383cdcd3b39dcc5\n","  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.9-cp37-none-any.whl size=46451 sha256=13d056c53c07385aa65cbf826c210bd6d5051a96f402cbeee464a6e4ee29c8be\n","  Stored in directory: /root/.cache/pip/wheels/5e/2e/f0/b07196e8c929114998f0316894a61c752b63bfa3fdd50d2fc3\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=2e884f6598a4c4e36ed3dd1295a09c92d0b57a4fe2bc78cf7a05013e7a6b4c2d\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built torchcontrib ftfy sacremoses\n","Installing collected packages: torchcontrib, spacy-alignments, ftfy, tokenizers, sacremoses, transformers, spacy-transformers, en-core-web-trf\n","Successfully installed en-core-web-trf-3.0.0 ftfy-5.9 sacremoses-0.0.43 spacy-alignments-0.7.2 spacy-transformers-1.0.1 tokenizers-0.9.4 torchcontrib-0.0.2 transformers-4.2.2\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_trf')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QiLkL9Le2b6u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614366231893,"user_tz":-330,"elapsed":5022,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"93497512-2d48-4e70-ab39-e380f5e03616"},"source":["!pip install Scrapy --upgrade"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting Scrapy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/16/3c7c37caf25f91aa21db194655515718c2a15f704f9f5c59a194f5c83db0/Scrapy-2.4.1-py2.py3-none-any.whl (239kB)\n","\r\u001b[K     |█▍                              | 10kB 11.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 13.1MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: queuelib>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (1.5.0)\n","Requirement already satisfied, skipping upgrade: protego>=0.1.15 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (0.1.16)\n","Requirement already satisfied, skipping upgrade: Twisted>=17.9.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (20.3.0)\n","Requirement already satisfied, skipping upgrade: parsel>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (1.6.0)\n","Requirement already satisfied, skipping upgrade: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (3.1)\n","Requirement already satisfied, skipping upgrade: pyOpenSSL>=16.2.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (19.1.0)\n","Requirement already satisfied, skipping upgrade: itemloaders>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (1.0.3)\n","Requirement already satisfied, skipping upgrade: PyDispatcher>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (2.0.5)\n","Requirement already satisfied, skipping upgrade: w3lib>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (1.22.0)\n","Requirement already satisfied, skipping upgrade: zope.interface>=4.1.3 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (5.1.0)\n","Requirement already satisfied, skipping upgrade: itemadapter>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (0.1.0)\n","Requirement already satisfied, skipping upgrade: service-identity>=16.0.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (18.1.0)\n","Requirement already satisfied, skipping upgrade: lxml>=3.5.0; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from Scrapy) (4.5.2)\n","Requirement already satisfied, skipping upgrade: cssselect>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (1.1.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from protego>=0.1.15->Scrapy) (1.15.0)\n","Requirement already satisfied, skipping upgrade: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->Scrapy) (20.2.0)\n","Requirement already satisfied, skipping upgrade: incremental>=16.10.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->Scrapy) (17.5.0)\n","Requirement already satisfied, skipping upgrade: Automat>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->Scrapy) (20.2.0)\n","Requirement already satisfied, skipping upgrade: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->Scrapy) (20.0.1)\n","Requirement already satisfied, skipping upgrade: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->Scrapy) (15.1.0)\n","Requirement already satisfied, skipping upgrade: PyHamcrest!=1.10.0,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->Scrapy) (2.0.2)\n","Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->Scrapy) (1.14.2)\n","Requirement already satisfied, skipping upgrade: jmespath>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders>=1.0.1->Scrapy) (0.10.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=4.1.3->Scrapy) (53.0.0)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->Scrapy) (0.2.8)\n","Requirement already satisfied, skipping upgrade: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->Scrapy) (0.4.8)\n","Requirement already satisfied, skipping upgrade: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->Scrapy) (2.10)\n","Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->Scrapy) (2.20)\n","Installing collected packages: Scrapy\n","  Found existing installation: Scrapy 2.3.0\n","    Uninstalling Scrapy-2.3.0:\n","      Successfully uninstalled Scrapy-2.3.0\n","Successfully installed Scrapy-2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I3_tmcWo2b6s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614366237379,"user_tz":-330,"elapsed":5521,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"4cbf9c4d-907e-468a-e0e8-12b97262e909"},"source":["!pip install stanza"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting stanza\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n","\r\u001b[K     |█▏                              | 10kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.7.1+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.49.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.24.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (53.0.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.25.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n","Installing collected packages: stanza\n","Successfully installed stanza-1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T79gn3Xp2b6v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614366240048,"user_tz":-330,"elapsed":2721,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"16a558f2-97fd-41e2-f6f6-b4cecf6d79f0"},"source":["!pip install unidecode"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.1.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oeCdp3Yfng6O"},"source":["----------- Restart Runtime ----------------"]},{"cell_type":"code","metadata":{"id":"SM7qufwE50Cz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361987802,"user_tz":-330,"elapsed":2227,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"2cc83a84-5ee9-491f-fdc0-1437d689abc3"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["pep.api  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3XjJFX7R-6ZV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361989388,"user_tz":-330,"elapsed":2455,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"61b68573-112e-452e-abe9-146652117c0b"},"source":["%cd /content/\r\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","pep.api  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AGHjajg1-6Zw"},"source":["!rm /content/pep.api/Code/result_database/database.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqz60fkTTC0g"},"source":["!rm /content/pep.api/Code/news_items.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-fCakJHYLud9","executionInfo":{"status":"ok","timestamp":1614361992251,"user_tz":-330,"elapsed":3213,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"5e08005a-aa67-418c-e9c7-816d19e2ec6e"},"source":["%%writefile /content/pep.api/Code/crawler/items.py\r\n","# Define here the models for your scraped items\r\n","#\r\n","# See documentation in:\r\n","# https://docs.scrapy.org/en/latest/topics/items.html\r\n","\r\n","import scrapy\r\n","\r\n","\r\n","class GovItem(scrapy.Item):\r\n","    # define the fields for your item here like:\r\n","    # name = scrapy.Field()\r\n","    pass\r\n","\r\n","class NewsItem(scrapy.Item):\r\n","    # define the fields for your item here like:\r\n","    # name = scrapy.Field()\r\n","    headline = scrapy.Field()\r\n","    url = scrapy.Field()\r\n","    # pass\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/crawler/items.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccdyYjffMMX7","executionInfo":{"status":"ok","timestamp":1614361994185,"user_tz":-330,"elapsed":4433,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"1a5f277b-2d75-4407-ee81-40c5a4937c57"},"source":["%%writefile /content/pep.api/Code/crawler/pipelines.py\r\n","# Define your item pipelines here\r\n","#\r\n","# Don't forget to add your pipeline to the ITEM_PIPELINES setting\r\n","# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\r\n","\r\n","\r\n","# useful for handling different item types with a single interface\r\n","from itemadapter import ItemAdapter\r\n","from scrapy import signals\r\n","from scrapy.exporters import CsvItemExporter\r\n","\r\n","\r\n","class GovPipeline:\r\n","    def process_item(self, item, spider):\r\n","        return item\r\n","\r\n","\r\n","class NewsPipeline(object):\r\n","\r\n","  def __init__(self):\r\n","    self.files = {}\r\n","\r\n","  @classmethod\r\n","  def from_crawler(cls, crawler):\r\n","    pipeline = cls()\r\n","    crawler.signals.connect(pipeline.spider_opened, signals.spider_opened)\r\n","    crawler.signals.connect(pipeline.spider_closed, signals.spider_closed)\r\n","    return pipeline\r\n","\r\n","  def spider_opened(self, spider):\r\n","    file = open('%s_items.csv' % spider.name, 'w+b')\r\n","    self.files[spider] = file\r\n","    self.exporter = CsvItemExporter(file)\r\n","    self.exporter.fields_to_export = ['headline', 'url']\r\n","    self.exporter.start_exporting()\r\n","\r\n","  def spider_closed(self, spider):\r\n","    self.exporter.finish_exporting()\r\n","    file = self.files.pop(spider)\r\n","    file.close()\r\n","\r\n","  def process_item(self, item, spider):\r\n","    self.exporter.export_item(item)\r\n","    return item"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/crawler/pipelines.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNdmrrSxMakx","executionInfo":{"status":"ok","timestamp":1614361994186,"user_tz":-330,"elapsed":3598,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"a59e741e-9c94-443a-d241-0cb2d80e9607"},"source":["%%writefile /content/pep.api/Code/crawler/settings.py\r\n","BOT_NAME = 'crawler'\r\n","SPIDER_MODULES = ['crawler.spiders']\r\n","NEWSPIDER_MODULE = 'crawler.spiders'\r\n","\r\n","DEPTH_LIMIT = 5           \r\n","LOG_ENABLED = True\r\n","CLOSESPIDER_TIMEOUT = 51*7200          #time in seconds (usually give 2 hours per site)\r\n","LOG_LEVEL = 'CRITICAL'\r\n","ROBOTSTXT_OBEY = False\r\n","CONCURRENT_ITEMS=32\r\n","\r\n","AUTOTHROTTLE_ENABLED = True\r\n","AUTOTHROTTLE_START_DELAY = 1\r\n","AUTOTHROTTLE_MAX_DELAY = 3\r\n","AUTOTHROTTLE_DEBUG = False\r\n","\r\n","DEPTH_PRIORITY = 1                      #settings for breadth first order\r\n","SCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleFifoDiskQueue'\r\n","SCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.FifoMemoryQueue'\r\n","\r\n","REDIRECT_ENABLED = False\r\n","\r\n","# LOG_FILE = 'logger.txt'            #uncomment this line and set LOG_LEVEL = 'DEBUG' from 'CRITICAL', to debug\r\n","\r\n","\r\n","# PROXY_POOL_ENABLED = True        # pip install scrapy_proxy_pool\r\n","\r\n","# DOWNLOADER_MIDDLEWARES = {\r\n","#     # ...\r\n","#     'scrapy_proxy_pool.middlewares.ProxyPoolMiddleware': 610,\r\n","#     'scrapy_proxy_pool.middlewares.BanDetectionMiddleware': 620,\r\n","#     # ...\r\n","# }\r\n","\r\n","\r\n","\r\n","# Scrapy settings for gov project\r\n","#\r\n","# For simplicity, this file contains only settings considered important or\r\n","# commonly used. You can find more settings consulting the documentation:\r\n","#\r\n","#     https://docs.scrapy.org/en/latest/topics/settings.html\r\n","#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\r\n","#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html\r\n","\r\n","# Crawl responsibly by identifying yourself (and your website) on the user-agent\r\n","#USER_AGENT = 'gov (+http://www.yourdomain.com)'\r\n","\r\n","# Obey robots.txt rules\r\n","# Configure maximum concurrent requests performed by Scrapy (default: 16)\r\n","#CONCURRENT_REQUESTS = 32\r\n","\r\n","# Configure a delay for requests for the same website (default: 0)\r\n","# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\r\n","# See also autothrottle settings and docs\r\n","#DOWNLOAD_DELAY = 3\r\n","# The download delay setting will honor only one of:\r\n","#CONCURRENT_REQUESTS_PER_DOMAIN = 16\r\n","#CONCURRENT_REQUESTS_PER_IP = 16\r\n","\r\n","# Disable cookies (enabled by default)\r\n","#COOKIES_ENABLED = False\r\n","\r\n","# Disable Telnet Console (enabled by default)\r\n","#TELNETCONSOLE_ENABLED = False\r\n","\r\n","# Override the default request headers:\r\n","#DEFAULT_REQUEST_HEADERS = {\r\n","#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\r\n","#   'Accept-Language': 'en',\r\n","#}\r\n","\r\n","# Enable or disable spider middlewares\r\n","# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\r\n","#SPIDER_MIDDLEWARES = {\r\n","#    'gov.middlewares.GovSpiderMiddleware': 543,\r\n","#}\r\n","\r\n","# Enable or disable downloader middlewares\r\n","# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\r\n","#DOWNLOADER_MIDDLEWARES = {\r\n","#    'gov.middlewares.GovDownloaderMiddleware': 543,\r\n","#}\r\n","\r\n","# Enable or disable extensions\r\n","# See https://docs.scrapy.org/en/latest/topics/extensions.html\r\n","#EXTENSIONS = {\r\n","#    'scrapy.extensions.telnet.TelnetConsole': None,\r\n","#}\r\n","\r\n","# Configure item pipelines\r\n","# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\r\n","#ITEM_PIPELINES = {\r\n","#    'gov.pipelines.GovPipeline': 300,\r\n","#}\r\n","\r\n","# Configure item pipelines\r\n","# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\r\n","ITEM_PIPELINES = {\r\n","   'crawler.pipelines.NewsPipeline': 300,\r\n","}\r\n","\r\n","# Enable and configure the AutoThrottle extension (disabled by default)\r\n","# See https://docs.scrapy.org/en/latest/topics/autothrottle.html\r\n","#AUTOTHROTTLE_ENABLED = True\r\n","# The initial download delay\r\n","#AUTOTHROTTLE_START_DELAY = 5\r\n","# The maximum download delay to be set in case of high latencies\r\n","#AUTOTHROTTLE_MAX_DELAY = 60\r\n","# The average number of requests Scrapy should be sending in parallel to\r\n","# each remote server\r\n","#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\r\n","# Enable showing throttling stats for every response received:\r\n","#AUTOTHROTTLE_DEBUG = False\r\n","\r\n","# Enable and configure HTTP caching (disabled by default)\r\n","# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\r\n","#HTTPCACHE_ENABLED = True\r\n","#HTTPCACHE_EXPIRATION_SECS = 0\r\n","#HTTPCACHE_DIR = 'httpcache'\r\n","#HTTPCACHE_IGNORE_HTTP_CODES = []\r\n","#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/crawler/settings.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlfHKO2UNS5E","executionInfo":{"status":"ok","timestamp":1614361994188,"user_tz":-330,"elapsed":3056,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"135cbc23-1f8d-4561-d790-d931cd0e67c6"},"source":["%%writefile /content/pep.api/Code/crawler/spiders/news_spider.py\r\n","\r\n","import os\r\n","import csv\r\n","\r\n","import scrapy\r\n","from bs4 import BeautifulSoup\r\n","# from news.items import NewsItem\r\n","from crawler.items import NewsItem\r\n","\r\n","def get_urls_from_csv():\r\n","    with open('websites.csv', 'rbU') as csv_file:\r\n","        data = csv.reader(csv_file)\r\n","        scrapurls = []\r\n","        for row in data:\r\n","            scrapurls.append(row)\r\n","        return scrapurls\r\n","\r\n","class NewsSpider(scrapy.Spider):\r\n","    name = \"news\"\r\n","    \r\n","    start_urls = [\r\n","                  \"https://economictimes.indiatimes.com/topic/\",\r\n","                  \"https://timesofindia.indiatimes.com/topic/\",\r\n","                  \"https://www.ndtv.com/search?searchtext=\",\r\n","                  \"https://indianexpress.com/?s=\",\r\n","                  \"https://www.hindustantimes.com/search?q=\",\r\n","                  \"https://www.thestatesman.com/?s=\",\r\n","                  \"https://www.telegraphindia.com/search?keyword=\",\r\n","                  \"https://www.dailypioneer.com/searchlist.php?search=\",\r\n","                  \"https://www.dailypioneer.com/searchlist.php?search=\",\r\n","                  \"https://www.dnaindia.com/search?query=\",\r\n","                  \"https://www.asianage.com/search?page=search&srh=news&search=\",\r\n","                  \"https://www.deccanherald.com/search?term=\",\r\n","                  \"https://www.business-standard.com/search?q=\",\r\n","    ]\r\n","    \r\n","    start_urls = [url+keyword for url in start_urls for keyword in ['black money',\r\n","                                                                    'money laundering', \r\n","                                                                    'money launder', \r\n","                                                                    'lauder the money', \r\n","                                                                    'money-mule', \r\n","                                                                    'money mule', \r\n","                                                                    'Hawala', \r\n","                                                                    'drug-trafficking', \r\n","                                                                    'drug trafficking', \r\n","                                                                    'terror', \r\n","                                                                    'terror financing'\r\n","    ]]\r\n","\r\n","    def parse(self, response):\r\n","      # text data of entire webpage\r\n","      soup = BeautifulSoup(response.text, 'html.parser') # parse\r\n","      # extract body from it\r\n","      soup = soup.body # scrape.parse_soup\r\n","\r\n","      all_links = soup.findAll(\"a\", href=True)\r\n","\r\n","      for link in all_links:\r\n","        news = NewsItem()\r\n","        if link.string and (response.url.split('/')[2] in link['href']):\r\n","          news['headline'] = link.string\r\n","          news['url'] = response.urljoin(link['href'])\r\n","\r\n","          yield news\r\n","\r\n","      # all_links = soup.findAll(\"a\", {'target': '_blank'})\r\n","\r\n","      # for link in all_links:\r\n","      #   news = NewsItem()\r\n","      #   news['headline'] = link.find('h2')\r\n","      #   if news['headline']:\r\n","      #     news['headline'] = news['headline'].string\r\n","      #     news['url'] = response.urljoin(link['href'])\r\n","\r\n","      #     yield news"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/crawler/spiders/news_spider.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fWfzmcdape3B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361994189,"user_tz":-330,"elapsed":2449,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"62cd492d-0382-40e4-da24-3365dc5ebb9b"},"source":["%%writefile /content/pep.api/Code/crawler/spiders/gov_spider.py\r\n","import scrapy\r\n","from bs4 import BeautifulSoup\r\n","import re\r\n","import pandas as pd\r\n","from urllib.parse import urlparse\r\n","from functions import pred\r\n","import scrape\r\n","from fake_headers import Headers\r\n","\r\n","class govSpider(scrapy.Spider):\r\n","    name = 'mygovscraper'\r\n","    max_retries = 2\r\n","    allowed_domains = []\r\n","    start_urls = []\r\n","    nations_dict = {}\r\n","    headergen = Headers(headers=True)\r\n","    english = ['en','english','eng','engl','angles','anglictina','engelsk','inglise','anglais','ingles','ingilizce','engelsk','anglictina','engleza','engelsk','inggeris','inggris','englisch','engels','engleski','angla','englanti','anglu','angielski','engels','chingerezi','inggris','enska','ingarihi','igilisi','parenglish']         #stay in english domains\r\n","    banned = ['state','how','map','pdf','program','news','press','topic','service','application','employment','immigration','law','public-health','symbol','function','environment','current-affairs','policy','resource','previous','mission','work','procure','alert','notice','guidance','foreign','catalogue','life','past','people','search','docs','cookies','interview','actual','publication','document','action','decision','gallery','museum','society','culture','foto','landmark','develop','publish','support','business','announcement','activ', 'archive', 'article', 'guideline','practice','procedure','chapter','scheme','report','spotlight','feedback','speech','blog','faq','covid','question','statement','permit','travel','living','apply','essence','advert','interest','tax','budget','bill','node','taxonomy','event','health-canada','gazette','classified','compilation','document','dokument','stats','contact','default','issue','agenda','history','visit','theme','tour','technology','glance','browse','debate','rules','involved','policies','countries','design','campaign','consult','sport','corporate','revenue','heritage','child','journal','portail','story','order','photo','statistics','drug'] #media,premier  #global stop words not to be crawled\r\n","    redirected = []\r\n","    def __init__(self, filename= 'news_items.csv', *args, **kwargs):\r\n","        super(govSpider, self).__init__(*args, **kwargs)\r\n","        self.retries = {}\r\n","        nations = pd.read_csv(filename,encoding= 'unicode_escape')\r\n","        print(nations)\r\n","\r\n","        if nations.isnull().any().any():\r\n","            pre=len(nations)\r\n","            nations.dropna(axis=0, how='any', inplace=True)\r\n","            print(f'Excluding {pre-len(nations)} NaN row(s) from {filename}')\r\n","\r\n","        for i in range(len(nations)):\r\n","            site = nations.iloc[i,1].strip()\r\n","            self.start_urls.append(site)\r\n","            for item in self.english:\r\n","                if item in site.lower().split('/'):\r\n","                    self.nations_dict[self.ret_domain(site)] = (nations.iloc[i,0].strip(),'en')\r\n","                    break\r\n","            else:\r\n","                self.nations_dict[self.ret_domain(site)] = (nations.iloc[i,0].strip(),None)\r\n","\r\n","            self.allowed_domains.append(urlparse(site).netloc) #keeps crawler within given domain\r\n","        print(f\"Crawler has started crawling with {len(self.start_urls)} inital site(s). Please wait for timeout or press ctrl+c repeatedly to force stop.\")\r\n","\r\n","    def ret_domain(self,site):                  # to get root domain of response url\r\n","        domain = urlparse(site).netloc\r\n","        if domain[:4]=='www.':\r\n","            return domain[4:]\r\n","        return domain\r\n","\r\n","    def ret_nation(self,domain):                # to extract nation from response url\r\n","        if len(domain)==0:\r\n","            return 0\r\n","        if domain in self.nations_dict.keys():\r\n","            return self.nations_dict[domain][0]\r\n","        else:\r\n","            if(len(domain.split('.',1))==1):\r\n","                return 0\r\n","            return self.ret_nation(domain.split('.',1)[1])\r\n","        \r\n","    def start_requests(self):                   #scrapy initiation function \r\n","        for url in self.start_urls:\r\n","            yield scrapy.Request(url=url,callback = self.parse, meta={'handle_httpstatus_list': [302, 307]}, headers = self.headergen.generate())\r\n","\r\n","    \r\n","    def parse(self,response):\r\n","        if response.status == 302 or response.status == 307:\r\n","            retries = self.retries.setdefault(response.url, 0)\r\n","            if retries < self.max_retries:\r\n","                self.retries[response.url] += 1\r\n","                yield response.request.replace(dont_filter=True)\r\n","            else:\r\n","                self.logger.error('%s still returns 302 responses after %s retries',\r\n","                                  response.url, retries)\r\n","            return\r\n","\r\n","        # self.logger.info(\"Scraped %s\", response.url)\r\n","        f = open('log.txt', 'a')\r\n","        f.write(\"Scraped {}\\n\".format(response.url))\r\n","        f.close()\r\n","        \r\n","        # print('soup object is created')\r\n","        soup = BeautifulSoup(response.text, 'html.parser')\r\n","        domain = self.ret_domain(response.url)\r\n","        nation = self.ret_nation(domain)\r\n","        # for item in self.banned:                #filtering stopwords for 1st visit\r\n","            # if item in response.url.lower(): \r\n","                # break\r\n","        # else:\r\n","            # scrape.parse_soup(domain,nation,response.url,soup)\r\n","        \r\n","        scrape.parse_soup(domain,nation,response.url,soup)\r\n","\r\n","        # for href in soup.find_all('a'):\r\n","            # try:\r\n","                # raw = href[\"href\"]\r\n","                # tag = href.text\r\n","            # except:\r\n","                # continue\r\n","            # if len(raw)==0 or 'javascript' in raw:\r\n","                # continue\r\n","\r\n","            # if(raw[0].isalpha() or raw[0]=='/'):     #to scrape valid websites only\r\n","                # new = response.urljoin(raw)\r\n","                # flag=0\r\n","                # if(pred(tag)) and (tag not in self.redirected):    #crawler intelligence\r\n","                  \r\n","                  # if self.nations_dict[domain][1] == 'en':\r\n","                    # for item in self.english:\r\n","                      # if item in new.lower().split('/'):\r\n","                        # flag=1\r\n","                    # elif self.nations_dict[domain][1] is None:\r\n","                        # flag=1\r\n","                    \r\n","                    # for item in self.banned:  #filtering stopwords for found urls\r\n","                      # if item in raw.lower():\r\n","                        # break\r\n","                    \r\n","                    # else:\r\n","                      # if flag==1: #do not scrape other languages\r\n","                        # self.redirected.append(tag)\r\n","                        # yield scrapy.Request(new, self.parse, meta={'handle_httpstatus_list': [302, 307]}, headers = self.headergen.generate())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/crawler/spiders/gov_spider.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u8pwyzUip7yS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361995044,"user_tz":-330,"elapsed":2480,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"8f445c70-c9c4-4d62-8660-105c0c9845f6"},"source":["%%writefile /content/pep.api/Code/scrape.py\r\n","from bs4 import BeautifulSoup\r\n","import requests\r\n","from functions import *\r\n","import pandas as pd\r\n","from csv import writer\r\n","import datetime\r\n","from unidecode import unidecode\r\n","\r\n","def returner(string):\r\n","  \r\n","    text = string['text']\r\n","    name = string['name']\r\n","    org = string['org']\r\n","    loc = string['loc']\r\n","    facebook_url = string['facebook_link']\r\n","    twitter_url = string['twitter_link']\r\n","    other_weblinks = string['other_weblinks']\r\n","    image_link = string['image_link']\r\n","    keywords = string['keyword']\r\n","    sources = string['sources']\r\n","    hdfc_present = string['hdfcpresent']\r\n","\r\n","    # prefix = ''\r\n","    # name = string['name']\r\n","    # ministry = string['org']\r\n","    # image_url = string['image_link']\r\n","    # facebook_url = string['facebook_link']\r\n","    # instagram_url = ''\r\n","    # twitter_url = string['twitter_link']\r\n","    # other_urls = string['other_weblinks']\r\n","\r\n","    # name=''\r\n","    # doc = nlp_Name(string)\r\n","    # for count,ent in enumerate(doc.ents):\r\n","    #     name+=ent.text+' '\r\n","    #     if count==0:\r\n","    #         break\r\n","    \r\n","    # doc =nlp_Min(string)\r\n","    # ministry=''\r\n","    # for ent in doc.ents:\r\n","    #     ministry+=ent.text+' '\r\n","    \r\n","    # doc =nlp_Pref(string)\r\n","    # prefix=''\r\n","    # for ent in doc.ents:\r\n","    #     prefix+=ent.text+' '\r\n","\r\n","    # prefix = ' '.join(prefix.split(' ')[:2])\r\n","    # name = ' '.join(name.split(' ')[:10])\r\n","    # name = ''.join(e for e in name if e.isalpha() or e == ' ')   #removing special chars, numbers and punctuations\r\n","    # ministry = ''.join(e for e in ministry if e.isalpha() or e == ' ')\r\n","    return name, org, loc, keywords, sources, hdfc_present\r\n","\r\n","def has_name(text):  #  name finder\r\n","    doc = nlp_Name(text)\r\n","    names = ''\r\n","    for ent in doc.ents:\r\n","        names += ent.text+' '\r\n","    names = names.strip()\r\n","    if names=='' or names.isnumeric():\r\n","        return 0\r\n","    return 1\r\n","\r\n","def scraper(url, domain, soup):\r\n","    \r\n","    result = []\r\n","\r\n","    # print('it is now inside scraper function')\r\n","    \r\n","    # false positives list\r\n","    fp_name = [\r\n","               \r\n","    ]\r\n","    \r\n","    fp_org = [\r\n","              \r\n","    ]\r\n","      \r\n","    # list of positions\r\n","    fp_loc = [\r\n","                 \r\n","    ]\r\n","    \r\n","    keywords = [\r\n","                'black money'\r\n","                'money laundering', \r\n","                'money launder', \r\n","                'lauder the money', \r\n","                'money-mule', \r\n","                'money mule', \r\n","                'Hawala', \r\n","                'drug-trafficking', \r\n","                'drug trafficking', \r\n","                'terror', \r\n","                'terror financing'\r\n","                ]\r\n","\r\n","    # extract body from it\r\n","    tag = soup.body # scrape.parse_sou\r\n","    \r\n","    # save data in profile\r\n","    profile = {'text': '', 'name': '', 'org': '', 'loc': '', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\r\n","    \r\n","    # iterate through each string\r\n","    for string in tag.stripped_strings:\r\n","      \r\n","      for keyword in keywords:\r\n","        if keyword in str(string).lower():\r\n","          if keyword not in profile['keyword']:\r\n","            profile['keyword'] += keyword + ', '\r\n","      \r\n","      if 'hdfc' in str(string).lower():\r\n","        profile['hdfcpresent'] = 'YES'\r\n","\r\n","      if len(string) > 540:\r\n","        continue\r\n","      \r\n","      # name extration through spacy model\r\n","      doc = nlp_Name(str(string))\r\n","      \r\n","      # iterate through each entity present\r\n","      for count,ent in enumerate(doc.ents):\r\n","        \r\n","        # find persons in text\r\n","        if ent.label_ == 'PERSON':\r\n","          \r\n","          # remove name if present in false positives\r\n","          if str(string) not in fp_name and (ent.text not in profile['name']):\r\n","            # print(str(string))\r\n","            profile['text'] = str(string)\r\n","            profile['name'] += ent.text + ', '\r\n","        \r\n","        # find persons in text\r\n","        elif ent.label_ == 'ORG':\r\n","          \r\n","          # remove name if present in false positives\r\n","          if str(string) not in fp_org and (ent.text not in profile['org']):\r\n","            profile['org'] += ent.text + ', '\r\n","          \r\n","          else:\r\n","            # print('Persons entity:', ent.text, ':', ent.label_)\r\n","            pass\r\n","        \r\n","        # find persons in text\r\n","        elif ent.label_ == 'GPE':\r\n","          \r\n","          # remove name if present in false positives\r\n","          if str(string) not in fp_loc and (ent.text not in profile['loc']):\r\n","            profile['loc'] += ent.text + ', '\r\n","    \r\n","    print(profile)\r\n","\r\n","    if profile['keyword']:\r\n","      result.append(profile)\r\n","      print(profile)\r\n","    \r\n","    return result\r\n","\r\n","def link_parser(links):\r\n","    img_formats = ['.jpg', '.jpeg', '.jpe', '.jif', '.jfif', '.jfi', '.png', 'webp', '.bmp', '.jp2', '.jpx', '.jpm', '.j2k']\r\n","    image_url, facebook_url, instagram_url, twitter_url, other_urls = '','','','',''\r\n","    for link in links:\r\n","        if 'javascript' in link:\r\n","            continue\r\n","        for imf in img_formats:\r\n","            if imf in link.lower():\r\n","                image_url+=link+' '\r\n","                break\r\n","        else:\r\n","            if 'facebook' in link.lower():\r\n","                facebook_url+=link+' '\r\n","            elif 'instagram' in link.lower():\r\n","                instagram_url+=link+' '\r\n","            elif 'twitter' in link.lower():\r\n","                twitter_url+=link+' '\r\n","            else:\r\n","                other_urls+=link+' '\r\n","    if len(other_urls.split(' '))>5:        #Removing excessive websites \r\n","        other_urls = ' '.join(other_urls.split(' ')[:4])\r\n","    return image_url, facebook_url, instagram_url, twitter_url, other_urls\r\n","\r\n","\r\n","def parse_soup(domain, nation, url, soup):\r\n","\r\n","    # print('it is now inside parse soup')\r\n","\r\n","    if soup is None:\r\n","        return\r\n","\r\n","    content =  scraper(url, domain, soup)\r\n","\r\n","    # if not content:\r\n","        # return \r\n","    #return content                         #debug statement\r\n","\r\n","    write_obj = open(\"result_database/database.csv\", 'a+', newline='',encoding='utf-8')\r\n","    csv_writer = writer(write_obj)\r\n","    for items in content:\r\n","        # print(' items :', items)\r\n","        name, org, loc, keywords, sources, hdfc_present = returner(items)        \r\n","        l1 = [name.strip(),org.strip(),loc.strip()]\r\n","        # if l1[0] == '' and l1[1] == '':     #no name no salutation //cleaner step\r\n","            # continue\r\n","        # if l1[1] in l1[2]:                  #name found in ministry //cleaner step\r\n","            # continue\r\n","        # if nation != 0:                     #0 if nation could not be retrieved from url\r\n","            # l1.append(nation)\r\n","        # else:\r\n","            # l1.append('')\r\n","        l1.append(datetime.datetime.now())  #timestamp\r\n","        # l1.append('PEP')                    #catagory\r\n","        # image_url, facebook_url, instagram_url, twitter_url, other_urls = link_parser(items[1])\r\n","        l1.extend((keywords, hdfc_present, url)) #urls\r\n","        print(l1)\r\n","        csv_writer.writerow(l1)\r\n","        row_count = sum(1 for line in open(filename))\r\n","    print('writing csv file')\r\n","    write_obj.close()\r\n","\r\n","\r\n","\r\n","# #for debugging:\r\n","# def main():\r\n","#     urls = [\"https://www.india.gov.in/my-government/whos-who/council-ministers\", \"https://www.gov.za/about-government/leaders\", \"https://uaecabinet.ae/en/cabinet-members\", \"https://www.india.gov.in/my-government/whos-who/chiefs-armed-forces\", \"https://www.india.gov.in/my-government/indian-parliament/lok-sabha\"]\r\n","#     url2 = \"https://www.india.gov.in/my-government/whos-who/council-ministers\"\r\n","#     site = requests.get(url2).content\r\n","#     soup = BeautifulSoup(site,\"html.parser\")\r\n","#     return(parse_soup('in','sw',url2, soup.body))\r\n","    \r\n","\r\n","# if __name__==\"__main__\":\r\n","#     res = main()\r\n","#     print(res)\r\n","\r\n","    \r\n","\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/scrape.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"roEAgo3hfxTm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361995049,"user_tz":-330,"elapsed":1760,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"4ed38fc9-0365-4c60-81ea-6e2b377e9791"},"source":["%%writefile /content/pep.api/Code/functions.py\r\n","import keras\r\n","import os\r\n","import spacy\r\n","import stanza\r\n","from pathlib import Path\r\n","import time\r\n","import warnings\r\n","import pandas as pd\r\n","from googletrans import Translator\r\n","from unidecode import unidecode\r\n","\r\n","stanza.download('en')\r\n","\r\n","nlp_Name = spacy.load(\"en_core_web_trf\") # spacy.load(OUTPUT1)\r\n","# nlp_Org = spacy.load(\"en_core_web_lg\") # spacy.load(OUTPUT1)\r\n","nlp_Org = stanza.Pipeline('en')\r\n","\r\n","# OUTPUT1='NER Models/Name/content/Model'\r\n","# OUTPUT2='NER Models/Prefix/content/Model'\r\n","# OUTPUT3='NER Models/Position Held/content/Model'\r\n","# OUTPUT4='NER Models/Intelligence/Model'\r\n","\r\n","# nlp_Name = spacy.load(OUTPUT1)\r\n","# nlp_Pref = spacy.load(OUTPUT2)\r\n","# nlp_Min = spacy.load(OUTPUT3)\r\n","# nlpIntel = spacy.load(OUTPUT4)\r\n","\r\n","#trans=Translator()          ###Only create instance once while loading in program else it automatically blocks IP if frequently used\r\n","\r\n","def translator(text):\r\n","    try:\r\n","        t=trans.translate(text)\r\n","        print(t.text)\r\n","    except:\r\n","        return text\r\n","    #print(t.src)\r\n","    #print(t.dest)\r\n","    #print(t.text)\r\n","    if t.src == 'en':\r\n","        return text\r\n","    return t.text\r\n","\r\n","def pred(tag):\r\n","    return 0\r\n","    # rtrn = 0\r\n","    # redirect = [\r\n","                # 'black money'\r\n","                # 'money laundering', \r\n","                # 'money launder', \r\n","                # 'lauder the money', \r\n","                # 'money-mule', \r\n","                # 'money mule', \r\n","                # 'Hawala', \r\n","                # 'drug-trafficking', \r\n","                # 'drug trafficking', \r\n","                # 'terror', \r\n","                # 'terror financing'\r\n","                # ]\r\n","    \r\n","    # print(tag)\r\n","\r\n","    # tag = tag.strip().lower()\r\n","    # tag = unidecode(tag)\r\n","    # tag = translator(tag)\r\n","    # stop_words = ['contact','citizenship','jobs','immigration','service','travel','security','apply','military','data','news','pension','travel','social','terms','media','twitter','where','mobile','treaties','covid','e-mail','search','healthy','quit','download','forum','veteran','information','detail','scheme','art','help','external website','register','communication','policy','policies','bill','form','affair','visit','grievance','access','publication','holiday','sitemap','mission','plan','pan','constitution','community','life','speech','service','gallery','rule','law']\r\n","    # hot_words = ['department','government','member','parties','party','federal','mp', 'lords','ministry','minister','cabinet','senat'] # Tuning the model\r\n","    # for hw in hot_words:\r\n","        # if hw in tag:\r\n","            # return 1\r\n","    # for sw in stop_words:\r\n","        # if sw in tag:\r\n","            # return 0\r\n","    # if(tag.isnumeric()):\r\n","        # return 1\r\n","        \r\n","    # doc = nlp_Name(tag)     #NLP model object\r\n","\r\n","    # for ent in doc.ents:\r\n","      # if ent.label_ == 'PERSON':\r\n","        # print('-------------------', tag, ':', ent.label_, '-----------------')\r\n","        # rtrn = 1\r\n","      # else:\r\n","        # pass\r\n","    \r\n","    # for _tag in redirect:\r\n","    #   if _tag in tag:\r\n","    #     print('----------------- tag in redirect:', tag, '------------')\r\n","    #     rtrn = 1\r\n","            \r\n","    # if tag in redirect:\r\n","      # print('------------------- tag in redirect:', tag, '------------')\r\n","      # rtrn = 1\r\n","    # elif tag.isdigit():\r\n","      # print('------------------- tag is digit:', tag, '---------------')\r\n","      # rtrn = 1\r\n","    # else:\r\n","      # rtrn = 0\r\n","    \r\n","    # return 1\r\n","\r\n","    # doc = nlpIntel(tag)     #NLP model object\r\n","\r\n","    # for ent in doc.ents:\r\n","        # if ent.text!=0:\r\n","            # print(tag)\r\n","            # return 1\r\n","    # return 0\r\n","\r\n","# def main():\r\n","#     tag = ''\r\n","#     print(pred(tag))\r\n","\r\n","# if __name__=='__main__':\r\n","#     main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/functions.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HlGdHa7K-81O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361995050,"user_tz":-330,"elapsed":1191,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"f7525d13-2f0e-401d-a569-52bc1af49c44"},"source":["%%writefile /content/pep.api/Code/postprocess.py\r\n","import pandas as pd\r\n","import math\r\n","import uuid\r\n","def postprocess():\r\n","    clean= ['Home','MPTrack','Shri','Smt','Dr','Mr','Mrs','Ms','cabinet','Minister','prime','Deputy','Ministry','Contact','Facebook','account','photo','mp','MP','Of','Biography','Email','Address','Roles','To','Read','more','Blog','Vacancies','Advertisement','Advertise','Office','Holding','Second','Member','Committee','Estimates','Fax','Find','Close','Links','Key','Figures','Stats','Statistics','Household','Full','name','Parks','Open','Menu','Languages','Opinion','Education','Address','Latest','Activity','Folketinget','Christiansborg','NA','PO','Father','Husband']\r\n","    banned = ['january','february','march','april','may','june','july','september','october','november','december','monday','tuesday','wednesday','thursday','friday','saturday','sunday','Party']\r\n","    try:\r\n","        df = pd.read_csv(\"result_database/database.csv\",names=['Person Name mentioned in the news','Organization Name mentioned in the news','City/ State mentioned under the news','Created_date_time','Key word Used for identify the article', 'HDFC Bank Name under News / Article', 'Web link of news'],encoding= 'unicode_escape')\r\n","    except Exception as e:\r\n","        print(e)\r\n","        return\r\n","    df = df.applymap(str)\r\n","    # df.replace(to_replace = 'nan', value = '', inplace = True)\r\n","    #print(\"Before cleaning: length =\",len(df))\r\n","    print(\"Postprocessing...\")\r\n","    \r\n","    # df.dropna(subset=['Person Name mentioned in the news'],inplace=True)\r\n","    # df.drop_duplicates(subset=['Person Name mentioned in the news'], keep='first',inplace=True)\r\n","    # df.reset_index(drop=True, inplace=True)\r\n","\r\n","    # for count,_ in enumerate(df['Person Name mentioned in the news']):\r\n","        # if  len(df['Person Name mentioned in the news'][count])<4:\r\n","            # df.drop(count,axis=0,inplace=True)\r\n","            # continue\r\n","        \r\n","        # for item in df['Person Name mentioned in the news'][count].split(' '):\r\n","            # if len(item)<2:\r\n","                # df.at[count, 'Person Name mentioned in the news'] = df['Person Name mentioned in the news'][count].replace(item,'')\r\n","            # for word in clean:\r\n","                # if word in item:\r\n","                    # new_val = df['Person Name mentioned in the news'][count].replace(word,'').strip()\r\n","                    # df.at[count, 'Person Name mentioned in the news'] = new_val\r\n","            # for ban in banned:\r\n","                # if ban in item.lower():\r\n","                    # df.drop(count,axis=0,inplace=True)\r\n","                    # break\r\n","            # else:\r\n","                # continue\r\n","            # break\r\n","                    \r\n","\r\n","    # df.dropna(subset=['Person Name mentioned in the news'],inplace=True)\r\n","    # df.drop_duplicates(subset=['Person Name mentioned in the news'], keep='first',inplace=True)\r\n","    # df.reset_index(drop=True, inplace=True)\r\n","    # uuids = []\r\n","    # for _ in range(len(df)):\r\n","        # uuids.append(uuid.uuid4().hex)\r\n","    # df.insert(0, '_id', uuids)\r\n","\r\n","    print(\"Postprocessing complete. Database contains {} rows\".format(len(df)))\r\n","    #print(\"After cleaning: length =\",len(df))\r\n","    df.to_csv(\"result_database/database.csv\",index=False)\r\n","    #df.transpose().to_json('./result_database/database.json',orient='table',index=False)  # to save as json\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/postprocess.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zaPU4PIHF2wP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361995542,"user_tz":-330,"elapsed":1184,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"ac1d9611-36e6-464f-fd9b-98e0b26c1826"},"source":["%%writefile /content/pep.api/Code/main.py\r\n","from twisted.internet import reactor, defer\r\n","from scrapy.crawler import CrawlerRunner\r\n","from scrapy.crawler import CrawlerProcess\r\n","from scrapy.utils.project import get_project_settings\r\n","from crawler.spiders.gov_spider import *\r\n","from crawler.spiders.news_spider import *\r\n","from postprocess import postprocess\r\n","import time\r\n","import os\r\n","\r\n","runner = CrawlerRunner(get_project_settings())\r\n","\r\n","@defer.inlineCallbacks\r\n","def crawl():\r\n","    print(\"==================== getting all the links to scrape ======================\")\r\n","    yield runner.crawl(NewsSpider)\r\n","    print(\"==================== Successfully saved all the links ======================\")\r\n","    yield runner.crawl(govSpider)\r\n","    reactor.stop()\r\n","\r\n","# crawl()\r\n","# reactor.run() # the script will block here until the last crawl call is finished\r\n","\r\n","def main():\r\n","    if not os.path.isdir(\"./result_database\"):\r\n","      os.makedirs(\"./result_database\")\r\n","    # process = CrawlerRunner(get_project_settings())\r\n","    # starting first spider\r\n","    # print(\"==================== getting all the links to scrape ======================\")\r\n","    # yield process.crawl(NewsSpider)\r\n","    # print(\"==================== Successfully saved all the links ======================\")\r\n","    # yield process.crawl(govSpider)\r\n","    # process.start()\r\n","    # process.stop()\r\n","    crawl()\r\n","    reactor.run() # the script will block here until the last crawl call is finished\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","  start = time.time()\r\n","  main()\r\n","  end = time.time()\r\n","  postprocess()\r\n","  print(\"Crawler ran for {} seconds\".format(round(end-start,0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/main.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XBp85KRXExd7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614361997036,"user_tz":-330,"elapsed":1051,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"5a01d71e-c812-405a-b92a-e139fe15dd19"},"source":["%cd /content/\r\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","pep.api  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSCbBwtBHMFs","executionInfo":{"status":"ok","timestamp":1614361997768,"user_tz":-330,"elapsed":1134,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"721d16c6-a640-4193-daad-4b8c0db20802"},"source":["%%writefile /content/pep.api/Code/starter_sites.csv\r\n","URL, Country\r\n","https://www.ndtv.com/india-news/enforcement-directorate-files-chargesheet-in-multi-crore-ponzi-scam-that-duped-lakhs-2362090, India\r\n","https://www.ndtv.com/india-news/court-frames-money-laundering-charges-against-om-prakash-chautala-2360599, India\r\n","https://www.ndtv.com/india-news/yes-bank-co-founder-rana-kapoor-arrested-in-alleged-rs-4-300-crore-fraud-2358949, India\r\n","https://www.ndtv.com/india-news/ex-trinamool-mp-kd-singh-sent-to-judicial-custody-in-money-laundering-case-2358918, India\r\n","https://www.ndtv.com/india-news/income-tax-body-detects-suspect-transactions-of-rs-300-crore-in-delhi-2345294, India\r\n","https://www.ndtv.com/india-news/hawala-dealer-naresh-jain-generated-black-money-worth-rs-565-crore-enforcement-directorate-2320129, India\r\n","https://www.ndtv.com/india-news/rs-62-crore-seized-after-multi-city-raids-on-hawala-operatives-report-2316889, India\r\n","https://www.ndtv.com/india-news/enforcement-directorate-names-hafiz-saeed-pak-aide-in-charge-sheet-in-terror-funding-case-2304034, India\r\n","https://www.ndtv.com/world-news/wife-of-mexican-drug-lord-el-chapo-arrested-in-us-2376444, India\r\n","https://www.ndtv.com/delhi-news/13-35-kg-heroin-1-kg-cocaine-seized-from-5-drug-traffickers-in-delhi-2363728, India\r\n","https://www.ndtv.com/india-news/drugs-worth-rs-165-crore-seized-in-manipur-6-arrested-2336175, India\r\n","https://www.ndtv.com/india-news/showik-chakraborty-denied-bail-part-of-chain-of-drug-dealers-high-court-2306538, India\r\n","https://www.ndtv.com/india-news/narcotics-control-bureau-busts-delhi-based-international-drug-trafficking-module-2299491, India\r\n","https://www.ndtv.com/world-news/chinese-prisoner-on-death-row-digs-100-feet-tunnel-to-escape-from-jail-cell-in-indonesia-2299312, India\r\n","https://www.ndtv.com/india-news/terrorism-continues-to-be-one-of-the-gravest-threats-to-humankind-s-jaishankar-2376909, India\r\n","https://www.ndtv.com/india-news/india-un-ambassador-ts-tirumurti-says-somalia-political-impasse-over-holding-of-election-disappointing-2376817, India\r\n","https://www.ndtv.com/india-news/bombay-high-court-upholds-bail-to-alleged-isis-terrorist-areeb-majeed-2376793, India"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/pep.api/Code/starter_sites.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"msKB99jLEbt9","colab":{"base_uri":"https://localhost:8080/","height":576},"executionInfo":{"status":"ok","timestamp":1614361998786,"user_tz":-330,"elapsed":1425,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"6a3bc8ee-10f5-403a-f76c-4883bef679f5"},"source":["import pandas as pd\r\n","\r\n","df = pd.read_csv('pep.api/Code/starter_sites.csv')\r\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>URL</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.ndtv.com/india-news/enforcement-di...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.ndtv.com/india-news/court-frames-m...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://www.ndtv.com/india-news/yes-bank-co-fo...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://www.ndtv.com/india-news/ex-trinamool-m...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.ndtv.com/india-news/income-tax-bod...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>https://www.ndtv.com/india-news/hawala-dealer-...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>https://www.ndtv.com/india-news/rs-62-crore-se...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>https://www.ndtv.com/india-news/enforcement-di...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>https://www.ndtv.com/world-news/wife-of-mexica...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>https://www.ndtv.com/delhi-news/13-35-kg-heroi...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>https://www.ndtv.com/india-news/drugs-worth-rs...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>https://www.ndtv.com/india-news/showik-chakrab...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>https://www.ndtv.com/india-news/narcotics-cont...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>https://www.ndtv.com/world-news/chinese-prison...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>https://www.ndtv.com/india-news/terrorism-cont...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>https://www.ndtv.com/india-news/india-un-ambas...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>https://www.ndtv.com/india-news/bombay-high-co...</td>\n","      <td>India</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  URL  Country\n","0   https://www.ndtv.com/india-news/enforcement-di...    India\n","1   https://www.ndtv.com/india-news/court-frames-m...    India\n","2   https://www.ndtv.com/india-news/yes-bank-co-fo...    India\n","3   https://www.ndtv.com/india-news/ex-trinamool-m...    India\n","4   https://www.ndtv.com/india-news/income-tax-bod...    India\n","5   https://www.ndtv.com/india-news/hawala-dealer-...    India\n","6   https://www.ndtv.com/india-news/rs-62-crore-se...    India\n","7   https://www.ndtv.com/india-news/enforcement-di...    India\n","8   https://www.ndtv.com/world-news/wife-of-mexica...    India\n","9   https://www.ndtv.com/delhi-news/13-35-kg-heroi...    India\n","10  https://www.ndtv.com/india-news/drugs-worth-rs...    India\n","11  https://www.ndtv.com/india-news/showik-chakrab...    India\n","12  https://www.ndtv.com/india-news/narcotics-cont...    India\n","13  https://www.ndtv.com/world-news/chinese-prison...    India\n","14  https://www.ndtv.com/india-news/terrorism-cont...    India\n","15  https://www.ndtv.com/india-news/india-un-ambas...    India\n","16  https://www.ndtv.com/india-news/bombay-high-co...    India"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"KY_sD-ByEeRh","colab":{"base_uri":"https://localhost:8080/","height":576},"executionInfo":{"status":"ok","timestamp":1614361999744,"user_tz":-330,"elapsed":1673,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"7579ef14-5c0e-471c-cbe3-21d0238bcee4"},"source":["# df = df[df['Country'] == 'India']\r\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>URL</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.ndtv.com/india-news/enforcement-di...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.ndtv.com/india-news/court-frames-m...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://www.ndtv.com/india-news/yes-bank-co-fo...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://www.ndtv.com/india-news/ex-trinamool-m...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.ndtv.com/india-news/income-tax-bod...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>https://www.ndtv.com/india-news/hawala-dealer-...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>https://www.ndtv.com/india-news/rs-62-crore-se...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>https://www.ndtv.com/india-news/enforcement-di...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>https://www.ndtv.com/world-news/wife-of-mexica...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>https://www.ndtv.com/delhi-news/13-35-kg-heroi...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>https://www.ndtv.com/india-news/drugs-worth-rs...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>https://www.ndtv.com/india-news/showik-chakrab...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>https://www.ndtv.com/india-news/narcotics-cont...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>https://www.ndtv.com/world-news/chinese-prison...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>https://www.ndtv.com/india-news/terrorism-cont...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>https://www.ndtv.com/india-news/india-un-ambas...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>https://www.ndtv.com/india-news/bombay-high-co...</td>\n","      <td>India</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  URL  Country\n","0   https://www.ndtv.com/india-news/enforcement-di...    India\n","1   https://www.ndtv.com/india-news/court-frames-m...    India\n","2   https://www.ndtv.com/india-news/yes-bank-co-fo...    India\n","3   https://www.ndtv.com/india-news/ex-trinamool-m...    India\n","4   https://www.ndtv.com/india-news/income-tax-bod...    India\n","5   https://www.ndtv.com/india-news/hawala-dealer-...    India\n","6   https://www.ndtv.com/india-news/rs-62-crore-se...    India\n","7   https://www.ndtv.com/india-news/enforcement-di...    India\n","8   https://www.ndtv.com/world-news/wife-of-mexica...    India\n","9   https://www.ndtv.com/delhi-news/13-35-kg-heroi...    India\n","10  https://www.ndtv.com/india-news/drugs-worth-rs...    India\n","11  https://www.ndtv.com/india-news/showik-chakrab...    India\n","12  https://www.ndtv.com/india-news/narcotics-cont...    India\n","13  https://www.ndtv.com/world-news/chinese-prison...    India\n","14  https://www.ndtv.com/india-news/terrorism-cont...    India\n","15  https://www.ndtv.com/india-news/india-un-ambas...    India\n","16  https://www.ndtv.com/india-news/bombay-high-co...    India"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"g2H-8-2cHZgj"},"source":["# df.loc[:, 'URL'] = 'https://www.ndtv.com/india-news/preparations-completed-mumbais-high-security-arthur-road-jail-awaits-nirav-modi-2379080'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jRE2pnV6IMQQ","colab":{"base_uri":"https://localhost:8080/","height":576},"executionInfo":{"status":"ok","timestamp":1614362002424,"user_tz":-330,"elapsed":3002,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"c32e16f3-2e20-4743-c97c-1fd97f8b5455"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>URL</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.ndtv.com/india-news/enforcement-di...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.ndtv.com/india-news/court-frames-m...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://www.ndtv.com/india-news/yes-bank-co-fo...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://www.ndtv.com/india-news/ex-trinamool-m...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.ndtv.com/india-news/income-tax-bod...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>https://www.ndtv.com/india-news/hawala-dealer-...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>https://www.ndtv.com/india-news/rs-62-crore-se...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>https://www.ndtv.com/india-news/enforcement-di...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>https://www.ndtv.com/world-news/wife-of-mexica...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>https://www.ndtv.com/delhi-news/13-35-kg-heroi...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>https://www.ndtv.com/india-news/drugs-worth-rs...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>https://www.ndtv.com/india-news/showik-chakrab...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>https://www.ndtv.com/india-news/narcotics-cont...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>https://www.ndtv.com/world-news/chinese-prison...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>https://www.ndtv.com/india-news/terrorism-cont...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>https://www.ndtv.com/india-news/india-un-ambas...</td>\n","      <td>India</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>https://www.ndtv.com/india-news/bombay-high-co...</td>\n","      <td>India</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  URL  Country\n","0   https://www.ndtv.com/india-news/enforcement-di...    India\n","1   https://www.ndtv.com/india-news/court-frames-m...    India\n","2   https://www.ndtv.com/india-news/yes-bank-co-fo...    India\n","3   https://www.ndtv.com/india-news/ex-trinamool-m...    India\n","4   https://www.ndtv.com/india-news/income-tax-bod...    India\n","5   https://www.ndtv.com/india-news/hawala-dealer-...    India\n","6   https://www.ndtv.com/india-news/rs-62-crore-se...    India\n","7   https://www.ndtv.com/india-news/enforcement-di...    India\n","8   https://www.ndtv.com/world-news/wife-of-mexica...    India\n","9   https://www.ndtv.com/delhi-news/13-35-kg-heroi...    India\n","10  https://www.ndtv.com/india-news/drugs-worth-rs...    India\n","11  https://www.ndtv.com/india-news/showik-chakrab...    India\n","12  https://www.ndtv.com/india-news/narcotics-cont...    India\n","13  https://www.ndtv.com/world-news/chinese-prison...    India\n","14  https://www.ndtv.com/india-news/terrorism-cont...    India\n","15  https://www.ndtv.com/india-news/india-un-ambas...    India\n","16  https://www.ndtv.com/india-news/bombay-high-co...    India"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"xCT3tdiwEgk2"},"source":["df.to_csv('pep.api/Code/starter_sites.csv', index=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9wO7HDtE4ql","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614362002439,"user_tz":-330,"elapsed":1469,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"cc180dc5-eb5f-46b0-81cd-7e47636e61c1"},"source":["%cd /content/pep.api/Code\r\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/pep.api/Code\n"," crawler        mygovscraper_items.csv\t __pycache__\t   starter_sites.csv\n"," functions.py  'NER Models'\t\t result_database   translate_manual.py\n"," log.txt        non_eng.csv\t\t scrape.py\n"," main.py        postprocess.py\t\t scrapy.cfg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9OSMaq0uE-2n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614362935943,"user_tz":-330,"elapsed":383385,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"304bdd9f-daed-4ed4-93d5-9c18658ab6ac"},"source":["%%time\r\n","!python main.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 42.0MB/s]        \n","2021-02-26 17:53:26 INFO: Downloading default packages for language: en (English)...\n","2021-02-26 17:53:28 INFO: File exists: /root/stanza_resources/en/default.zip.\n","2021-02-26 17:53:33 INFO: Finished downloading models and saved to /root/stanza_resources.\n","2021-02-26 17:53:38 INFO: Loading these models for language: en (English):\n","=========================\n","| Processor | Package   |\n","-------------------------\n","| tokenize  | combined  |\n","| pos       | combined  |\n","| lemma     | combined  |\n","| depparse  | combined  |\n","| sentiment | sstplus   |\n","| ner       | ontonotes |\n","=========================\n","\n","2021-02-26 17:53:38 INFO: Use device: cpu\n","2021-02-26 17:53:38 INFO: Loading: tokenize\n","2021-02-26 17:53:38 INFO: Loading: pos\n","2021-02-26 17:53:38 INFO: Loading: lemma\n","2021-02-26 17:53:38 INFO: Loading: depparse\n","2021-02-26 17:53:39 INFO: Loading: sentiment\n","2021-02-26 17:53:40 INFO: Loading: ner\n","2021-02-26 17:53:41 INFO: Done loading processors!\n","==================== getting all the links to scrape ======================\n","==================== Successfully saved all the links ======================\n","                                         headline                                                url\n","0                                            NDTV                              https://www.ndtv.com/\n","1                                        Business  https://www.ndtv.com/business/?pfrom=ndtv-glob...\n","2                                          Movies  https://www.ndtv.com/entertainment/?pfrom=ndtv...\n","3                                        Shopping  https://www.ndtv.com/shopping/?pfrom=ndtv-glob...\n","4                                           Beeps   https://www.ndtv.com/beeps/?pfrom=ndtv-globalnav\n","...                                           ...                                                ...\n","4024  Here are the dates for state assembly polls  https://www.deccanherald.com/national/national...\n","4025    Khashoggi death report to be declassified  https://www.deccanherald.com/international/wor...\n","4026                                 Bharat Bandh  https://www.deccanherald.com/national/bharat-b...\n","4027   New Guidelines social media, OTT platforms  https://www.deccanherald.com/national/centre-l...\n","4028                            Centre vs Farmers        https://www.deccanherald.com/tag/farm-bills\n","\n","[4029 rows x 2 columns]\n","Crawler has started crawling with 4029 inital site(s). Please wait for timeout or press ctrl+c repeatedly to force stop.\n","{'text': \"Mukesh Ambani Is Richest Asian Again As China's Zhong Loses $22 Billion\", 'name': \"Swasth, Corona, Mamata Banerjee, Modi, Virat Kohli's, Nirav Modi, Mukesh Ambani, Yusuf Pathan, Arvind Kejriwal, Zhong, \", 'org': 'NDTV, BCCI, BJP, AAP, ', 'loc': 'INDIA, Bengal, Singhu, Sri Lanka, China, India, Assam, Ahmedabad, Mumbai, Delhi, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': '\"Tears Make It Hard To Type\" For Babil, Who Saw Dad Irrfan In His Dream', 'name': \"Swasth, Rakhi Sawant's, Salman, Meghan Markle, Bipasha Basu, Babil, Abhay Deol, Shahid Kapoor, Mira Rajput, Deepika, The Girl On The Train, Parineeti, Shilpa Shetty's, Pulkit, Kriti, Kim, Ileana D'Cruz, Diana, Uptown Girl, Khushi, The New, Shanaya Kapoor, Demi Moore's, Disha Patani, Varun Dhawan, Ki Dulhania, Isabelle Kaif, Sooraj Pancholi, Rajkummar Rao's, Richa Chadha, Tandav, Saif Ali Khan, Dimple Kapadia, Kajol, Priyanka-Rajkummar's, The White Tiger, Rana Daggubati's, Haathi Mere Saathi, Drishyam 2, Mads Mikkelsen, Deepika Padukone, Ranveer Singh, Rahul Vaidya, Disha Parmar, Sunny Leone, Janhvi Kapoor, Kiara Advani, Alia Bhatt, Sanjay Leela Bhansali's, Tiger Shroff, Varun Sharma, Arjun Kapoor, Malaika Arora, Kareena Kapoor, Saif Ali Khan's, Neetu Kapoor's, Riddhima, Samara, Shilpa-Raj, Aly-Jasmin, Bigg Boss 14, Son Taimur, Karisma Kapoor, Randhir Kapoor, Sushmita Sen, Daisy Shah, Nora Fatehi, Parineeti Chopra, Aditi Rao Hydari, Joyce, Arhaan, Kriti Kharbanda, Pooja Hegde, Shehnaaz Gill, Ananya Panday And, Jasmin Bhasin, Ibrahim, Ranbir, Dia Mirza, Vaibhav Rekhi, Samisha, Kareena-Saif, Alia-Ranbir, Tara-Aadar, Randhir Kapoor's, Siddhant, Ishaan, Karan Johar's, Disha-Tiger, Malaika-Arjun, Sara, Varun Dhawan's, Khushi Kapoor, Sanya Malhotra, Deepika Padukone's, Aaj Kal, Vaani Kapoor, Neha Dhupia, Chitrangada Singh, Rajiv Kapoor's, Shah Rukh Khan, Mouni, Gauri-AbRam, Kareena-Taimur, Yash, Roohi, Aamir Khan's, Kiran Rao, Ira, Azad, Hrithik Roshan, Sussanne, Sanjay Khan's, Natasha Dalal, Anjini Dhawan, Hansika Motwane, Sussanne Khan, Abhishek Bachchan, Dhoom Machale, Priyaank Sharma And, Shaza Morani, Shraddha Kapoor, Anil Kapoor, Juhi Chawla, The Girl On The Plane, Raveena Tandon, Bunty Walia's, Manushi Chhillar, Vicky Kaushal, Farhan, Arbaaz, Kartik Aaryan, John Abraham's, Kangana Ranaut, Suniel Shetty's, Sara Ali Khan, Manish Malhotra's, Kriti Sanon, Sonu Sood, Salman Khan, Tom, Pooja Bedi, Alaya Furniturewalla, Manya Singh, Tim Story, Pallavi Sharda, Ishaan Khatter, Nick Jonas', Krishna Shroff, Aditya Narayan's, Shweta, Lata Mangeshkar, Padmini, Leena Chandavarkar, Gangubai Kathiawadi, Irrfan, \", 'org': 'NDTV, ', 'loc': 'Maldives, Roohi, Chembur, Dhanipur Airstrip, Mumbai, Bipasha, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Nilgiri Touch Winter Green Oil (Gaultheria, Joint Pain Oil) 1000 ml', 'name': \"Swasth, Disha Patani, Kiara Advani, Neha Kakkar's, BS Yediyurappa, Dharmendra, Akshay Kumar, Anil Panachooran, Ravichandran Ashwin, Malaika Arora, Arjun Kapoor, Kurtas, Nilgiri, \", 'org': 'NDTV, Samsung, Mercedes, IIT Goa, Redmi, bluehole studio inc, PUBG, Infinix, Realme, Marshall, Lenovo, Jabra, Wahl, LG, Bose, Wildcraft, Maybelline, NDTV Shopping, ', 'loc': 'India, Goa, Karnataka, Delhi, Australia, Sydney, Denmark, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Things To Do In Jim Corbett', 'name': \"Swasth, Corona, Sara Ali Khan's, Ileana D'Cruz, Diana, Uptown Girl, Deepika Padukone's, Ranveer Singh, Kareena, Karisma Kapoor, Realme Narzo, Jim Corbett, \", 'org': 'NDTV, Poco, Samsung, Realme, ', 'loc': 'INDIA, India, England, Jaipur, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Corona', 'name': 'Swasth, Corona, ', 'org': 'NDTV, ', 'loc': 'INDIA, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Swasth', 'name': 'Swasth, ', 'org': 'NDTV, NDTV News, NDTV 24x7, NDTV India, NDTV Profit, NDTV News-, NDTV News App, NDTV Lite, NDTV Cricket, NDTV Gadgets, Flipkart, Amazon, NDTV Convergence Limited, ', 'loc': 'India, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Watch: Prannoy Roy Explains Budget 2019 In 10 Points', 'name': \"Swasth, Akhilesh Yadav, Nikita Prasad, Naresh Jain, Rahul Gandhi, Manish Kumar, Divyanshu Dutta Roy, Narendra Modi, Jumla, Akhilesh Sharma, Shylaja Varma, Akhil Arora, Rhea Chakraborty's, Modi-ji, Mamata Banerjee, Prannoy Roy, \", 'org': 'NDTV, Press Trust of India, The Income Tax Department, the Central Board of Direct Taxes, CBDT, Delhi News, Samajwadi Party, the Enforcement Directorate, ED, Congress, BJP, Punjab Youth Congress, Netflix, SBI, Trinamool, NDTV Convergence Limited, Flipboard Magazine, ', 'loc': 'India, Pune, Bengaluru, Kolkata, Tamil Nadu, Delhi, Hawala, Bihar, Switzerland, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Amit Shah Reviews COVID-19 Situation As Some States Report Rise In Cases', 'name': 'Swasth, Amit Shah, ', 'org': 'NDTV, Pfizer, Bharat Biotech, ', 'loc': 'Hindi, UK, India, Brazil, Mumbai, Covid, Maharashtra, China, Tamil Nadu, US, Bengaluru, Patanjali, Wuhan, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Yuva', 'name': \"Swasth, Aaditya Thackeray, Nodeep Kaur, Nirav Modi, Mukul Rohatgi, Mukesh Ambani's, Rahul Gandhi, Tejashwi Yadav's, Mamata Banerjee's, Arvind Kejriwal's, Narendra Modi, Akash Ambani, Shloka Mehta, Priyanka Chopra, Nick Jonas, Deepika-Ranveer Singh's, Dhadak, Janhvi Kapoor, Ishaan Khatter, Indian Of The Year, Indianama, Issi Ka Naam Zindagi, Ki Baat, Aaj Ka Agenda, Abki Baar, Kiski Sarkar, Badi Khabar, Behtar, Bihar Ka Dangal, Hin, Chai Pe Charcha, Chalte Chalte, Chhupa Rustam, Chunaavi Jung, Afwah Banam Haqiqat, Cycle Of Change, Des Ki Baat, Dilli Ka Dangal, Randeep Guleria, Siddharth Vinayak Patankar, Green Champion, Gujarat Ka Garh, Gustakhi Maaf, Gutthi, Humaari Betiyaan, Jaano Apne, Jai Jawan, Jock The Talk, Khabron Ki Khabar, Kiski Daal Galegi, Karan, Kushalta Ke Kadam, Limelight, Maa Ganga, Maha Muqabla, Mandy, Meri Aawaaz Suno, Meri Udaan, Mojarto, MoJo, Mukhyamantri Chale Gaon, New Kids On The Block, Padharo Mahare Desh, Person Of Interest, Patnaik, Power Of One, Vikram Chandra, Ranneeti, Ravish Ki, Roshan Dilli, Salaam Zindagi, Sapnon Ki Udaan, Shiksha Ki Ore, Siyasat, Sunday Best, Tamasha, The Economic Matrix, The Election Express, The Great Indian Tamasha, The Hot Seat, The Music Hour, The Rising Stars Of Comedy, The Third Eye, The Unstoppable Indians, The World This Week, Vinod Dua, Ka Dum, Watan Ke Rakhwale, Women Of Worth, Nahin Aasaan, Youth For Change, Yuva, \", 'org': \"NDTV, CoWin, Amazon, BJP, Khelo India Winter Games, Samsung, NDTV 24x7, NDTV India, India Inc, India Inc's, Indie Film Club, City Express, Hindustan Times Leadership Summit, Nasdaq, NDTV Special, NDTV Tech Conclave, NDTV Yuva, NDTV-Fortis Health4U, News 360, Newstime India, NSE, Sawaal India Ka, The Election Centre, The Village Voice, Yeh Film, Youth For Change, NDTV Convergence Limited, \", 'loc': \"India, London, Singhu, Delhi, Mumbai, Maharashtra, UK, Bengal, Tamil Nadu's, Surat, Baba Ka Dhaaba, Banega Swasth India, Bano India, Desh Pradesh, New Zealand, Kurukshetra, Mahindra, Davos, Paksh Vipaksh, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Opinion: The Absolutely Justifiable Renaming Of Stadium After PM Modi', 'name': 'Swasth, Corona, Bhoomika Aggarwal, AP Kanvinde, Michael Vaughan, Mukesh Ambani, Zhong Shanshan, Venus Feng, Christian Michel, Munawar Faruqui, Arvind Kejriwal, Akhilesh Sharma, Divyanshu Dutta Roy, Mamata Banerjee, Modi, ', 'org': 'NDTV, IIT Roorkee, AP Kanvinde Memorial Lecture Series, Indian Institute of Technology, Department of Architecture and Planning, BCCI, Board of Control for Cricket in India, Bloomberg, UN Human Rights Council, UNHRC, The Indian Institute of Technology Bombay, Centre, Delhi High Court, the Working Group on Arbitrary Detention, AgustaWestland, AAP, BJP, Congress, the Union Ministry of Health and Family Welfare, MoHFW, the Madhya Pradesh High Court, NorthEast United FC, Kerala Blasters FC, Indian Super League, ISL, Agence France-Presse, the Aam Aadmi Party, ', 'loc': \"INDIA, India, England, Ahmedabad, China, Sri Lanka's, Beijing, New Delhi, Indore, Odisha, Gujarat, Surat, Bengal, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': '\"Is It On PM\\'s Suggestion?\" Mamata Banerjee Slams Bengal\\'s Marathon Polls', 'name': \"Swasth, Corona, Mukesh Ambani, Zhong Shanshan, Venus Feng, Christian Michel, Munawar Faruqui, Arvind Kejriwal, Akhilesh Sharma, Divyanshu Dutta Roy, Nodeep Kaur's, Rajvir Kaur, Alok Pandey, Stela Dey, Shivraj Chouhan, Shivraj Singh Chouhan, Modi, Deep Sidhu's, Mohammad Ghazali, Mamata Banerjee, \", 'org': 'NDTV, Bloomberg, Centre, Delhi High Court, UN, the Working Group on Arbitrary Detention, AgustaWestland, AAP, BJP, Congress, the Union Ministry of Health and Family Welfare, MoHFW, the Madhya Pradesh High Court, the Aam Aadmi Party, ', 'loc': \"INDIA, India, China, New Delhi, Indore, Gujarat, Surat, Muzaffarnagar, Uttar Pradesh's, Bhopal, Mumbai, Singhu, Ahmedabad, Bengal, England, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Ravish Kumar', 'name': \"Swasth, Corona, Modi, Mukul Kesavan, Avni, Swati Thiyagarajan, Andy Mukherjee, Narendra Modi, Vallabhbhai Patel, Sardar Patel, Sunita Dongre, Rajmohan Gandhi, Disha Ravi's, Yashwant Sinha, Aunindyo Chakravarty, David Fickling, Shah, Ramachandra Guha, Sitharaman, Praveen Chakravarty, Manmohan Singh, Akshay Dongare, Ashwini Mehra, Brinda Karat, Chandan Mitra, Derek O'Brien, Maitreesh Ghatak, Mani Shankar Aiyar, Mihir Swarup Sharma, Shobhaa De, Swati Chaturvedi, AN Roy, AP Singh, Aaditya Thackeray, Abishek Venkataraman, Aditya Thackeray, Manmohan Bahadur VM, Ajay Mankotia, Akshat Khandelwal, Ali Salman Alvi, Alok Pandey, Aman Sinha, Amandeep Singh Dhaliwal, Amit Basole, Arjun Jayadev, Amitoj Singh, Anam Mirza, Anand Kumar, Anand Teltumbde, Anant R Zanane, Ananya Singh, Andrew Whitehead, Aneesha Baig, Anjali Nayyar, Ankit Lal, Anu Aggarwal, Anupam Manur, Anurag Mehra, Chetan Bhattacharji, Nazir Masoodi, Maya Sharma, Raghunath Nambiar, Pallava Bagla, Neeta Sharma, Dhiraj Kukreja, Rica Roy, Manish Kumar, Rohit Khilnani, Vishal K. Dev, Jyotsna Mohan Bhargava, IP Bajpai, Uma Sudhir, Saurabh Gupta, Karan Chopra, Dorab R Sopariwala, Soni Varghese, Aryaan Mehra, Sukirti Dwivedi, Sonal Joshi, Tejas Mehta, Radhika Naidu, Sunetra Choudhury, Ravish Kumar, \", 'org': 'NDTV, Bloomberg, the Supreme Court, NBC News, BJP, Standard Oil Co., Parliament, United Progressive Alliance, UPA, RBI, Bloomberg Opinion, ', 'loc': \"INDIA, Singapore, Gujarat, India, US, New Delhi's, U.S., America, Punjab, Texas, Mumbai, Kolkata, Hyderabad, Noida, Uttarakhand, Kedarnath, Dhaval Kothari, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': '\"Is It On PM\\'s Suggestion?\" Mamata Banerjee Slams Bengal\\'s Marathon Polls', 'name': \"Swasth, Corona, Alok Pandey, Stela Dey, Nirav Modi, Mukesh Singh Sengar, Vaibhav Tiwari, Kishori Pednekar, Mukesh Ambani's, Sunilkumar M Singh, Divyanshu Dutta Roy, Anil Deshmukh, Debanish Achom, Arvind Kejriwal, Raghav Chadha, Mamata Banerjee, \", 'org': 'NDTV, Agra News, Ahmedabad News, Allahabad News, Delhi News, Ghaziabad News, Hyderabad News, Jammu News, Lucknow News, Meerut News, Mumbai News, Noida News, Surat News, Punjab National Bank, PNB, the Brihanmumbai Municipal Corporation, BMC, Delhi Jal Board, the India Meteorological Department, IMD, the Punjab State Power Corporation Limited, PSPCL, BJP, AAP, ', 'loc': \"INDIA, Amritsar, Aurangabad, Bengaluru, Bhopal, Bhubaneshwar, Chandigarh, Chennai, Gurgaon News, Guwahati, Jaipur, Kanpur, Kolkata, Ludhiana, Muzaffarnagar, Nagpur, Patna News, Srinagar, Delhi, New Delhi, Uttar Pradesh's, Mumbai, UK, India, Covid, Maharashtra, Punjab, England, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': 'money launder, ', 'sources': '', 'hdfcpresent': 'No'}\n","{'text': '\"Is It On PM\\'s Suggestion?\" Mamata Banerjee Slams Bengal\\'s Marathon Polls', 'name': \"Swasth, Corona, Alok Pandey, Stela Dey, Nirav Modi, Mukesh Singh Sengar, Vaibhav Tiwari, Kishori Pednekar, Mukesh Ambani's, Sunilkumar M Singh, Divyanshu Dutta Roy, Anil Deshmukh, Debanish Achom, Arvind Kejriwal, Raghav Chadha, Mamata Banerjee, \", 'org': 'NDTV, Agra News, Ahmedabad News, Allahabad News, Delhi News, Ghaziabad News, Hyderabad News, Jammu News, Lucknow News, Meerut News, Mumbai News, Noida News, Surat News, Punjab National Bank, PNB, the Brihanmumbai Municipal Corporation, BMC, Delhi Jal Board, the India Meteorological Department, IMD, the Punjab State Power Corporation Limited, PSPCL, BJP, AAP, ', 'loc': \"INDIA, Amritsar, Aurangabad, Bengaluru, Bhopal, Bhubaneshwar, Chandigarh, Chennai, Gurgaon News, Guwahati, Jaipur, Kanpur, Kolkata, Ludhiana, Muzaffarnagar, Nagpur, Patna News, Srinagar, Delhi, New Delhi, Uttar Pradesh's, Mumbai, UK, India, Covid, Maharashtra, Punjab, England, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': 'money launder, ', 'sources': '', 'hdfcpresent': 'No'}\n","[\"Swasth, Corona, Alok Pandey, Stela Dey, Nirav Modi, Mukesh Singh Sengar, Vaibhav Tiwari, Kishori Pednekar, Mukesh Ambani's, Sunilkumar M Singh, Divyanshu Dutta Roy, Anil Deshmukh, Debanish Achom, Arvind Kejriwal, Raghav Chadha, Mamata Banerjee,\", 'NDTV, Agra News, Ahmedabad News, Allahabad News, Delhi News, Ghaziabad News, Hyderabad News, Jammu News, Lucknow News, Meerut News, Mumbai News, Noida News, Surat News, Punjab National Bank, PNB, the Brihanmumbai Municipal Corporation, BMC, Delhi Jal Board, the India Meteorological Department, IMD, the Punjab State Power Corporation Limited, PSPCL, BJP, AAP,', \"INDIA, Amritsar, Aurangabad, Bengaluru, Bhopal, Bhubaneshwar, Chandigarh, Chennai, Gurgaon News, Guwahati, Jaipur, Kanpur, Kolkata, Ludhiana, Muzaffarnagar, Nagpur, Patna News, Srinagar, Delhi, New Delhi, Uttar Pradesh's, Mumbai, UK, India, Covid, Maharashtra, Punjab, England,\", datetime.datetime(2021, 2, 26, 18, 0, 6, 272808), 'money launder, ', 'No', 'https://www.ndtv.com/cities']\n","writing csv file\n","{'text': \"BJP Truth Bombs For AAP's Surat Bash Get Quick Arvind Kejriwal Comebacks\", 'name': 'Swasth, Corona, Alexei Navalny, Prince Harry, Neera Tanden, Biden, Trump, Donald Trump, Mamata Banerjee, Modi, Arvind Kejriwal, ', 'org': \"NDTV, UN Human Rights Council, UNHRC, Agence France-Presse, United Nations, The UN Security Council, WHO, Reuters, the World Health Organization, Chinese Sinopharm's, Oxford AstraZeneca, Pfizer, BioNtech, ISIS, Islamic State, Boeing, Boeing Co, White House, The White House, the Office of Management and Budget, Congress, the Capitol Police, BJP, AAP, \", 'loc': \"INDIA, China, Sri Lanka's, Beijing, United States, Dubai, Saudi Arabia, Singapore, Geneva, Russia, India, Colombo, Nigeria, Kano, UK, London, Kremlin, Moscow, Taiwan, Taipei, United Kingdom, Britain, the United States, Australia, Sydney, Washington, Bengal, England, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': '', 'name': '', 'org': 'Twitter, Inc., ', 'loc': '', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': \"BJP Truth Bombs For AAP's Surat Bash Get Quick Arvind Kejriwal Comebacks\", 'name': \"Swasth, Corona, Sheryl Sandberg, Sanya Jain, Tom Bernthal, Mona Singh, Sam Jawed, Tim Cook, Steve Jobs, Vidam Perevertilov, Bob Barnard, Elon Musk, Peter Schiff, Joe Biden's, Chrissy Teigen, Sania Mirza, Anam Mirza, Mamata Banerjee, Modi, Arvind Kejriwal, \", 'org': 'NDTV, Facebook, Prega News, Agence France-Presse, Twitter, Apple, Fox5, Tesla, SpaceX, Euro Pacific Capital, NSE, the National Stock Exchange, BJP, AAP, ', 'loc': \"INDIA, Australia, Melbourne, Amritsar, India, England, Ahmedabad, Bollywood, New Zealand's, Tauranga, Pitcairn Island, Virginia, Arizona, Coolidge, US, Bengal, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': \": Janhvi Kapoor And Ishaan Khatter's Tale Of Love And Heartbreak\", 'name': \"Swasth, Indian Of The Year, Indianama, Issi Ka Naam Zindagi, Ki Baat, Aaj Ka Agenda, Abki Baar, Kiski Sarkar, Badi Khabar, Behtar, Bihar Ka Dangal, Hin, Chai Pe Charcha, Chalte Chalte, Chhupa Rustam, Chunaavi Jung, Afwah Banam Haqiqat, Cycle Of Change, Des Ki Baat, Dilli Ka Dangal, Randeep Guleria, Siddharth Vinayak Patankar, Green Champion, Gujarat Ka Garh, Gustakhi Maaf, Gutthi, Humaari Betiyaan, Jaano Apne, Jai Jawan, Jock The Talk, Khabron Ki Khabar, Kiski Daal Galegi, Karan, Kushalta Ke Kadam, Limelight, Maa Ganga, Maha Muqabla, Mandy, Meri Aawaaz Suno, Meri Udaan, Mojarto, MoJo, Mukhyamantri Chale Gaon, New Kids On The Block, Padharo Mahare Desh, Person Of Interest, Patnaik, Power Of One, Vikram Chandra, Ranneeti, Ravish Ki, Roshan Dilli, Salaam Zindagi, Sapnon Ki Udaan, Shiksha Ki Ore, Siyasat, Sunday Best, Tamasha, Modi, The Economic Matrix, The Election Express, The Great Indian Tamasha, The Hot Seat, The Music Hour, The Rising Stars Of Comedy, The Third Eye, The Unstoppable Indians, The World This Week, Vinod Dua, Ka Dum, Watan Ke Rakhwale, Women Of Worth, Nahin Aasaan, Youth For Change, Yuva, Aaditya Thackeray, Nodeep Kaur, Nirav Modi, Mukul Rohatgi, Mukesh Ambani's, Rahul Gandhi, Tejashwi Yadav's, Mamata Banerjee's, Arvind Kejriwal's, Narendra Modi, Akash Ambani, Shloka Mehta, Priyanka Chopra, Nick Jonas, Deepika-Ranveer Singh's, Dhadak, Janhvi Kapoor, Ishaan Khatter, \", 'org': \"NDTV, Samsung, NDTV 24x7, NDTV India, India Inc, India Inc's, Indie Film Club, City Express, Hindustan Times Leadership Summit, Nasdaq, NDTV Special, NDTV Tech Conclave, NDTV Yuva, NDTV-Fortis Health4U, News 360, Newstime India, NSE, Sawaal India Ka, The Election Centre, The Village Voice, Yeh Film, Youth For Change, CoWin, Amazon, BJP, Khelo India Winter Games, NDTV Convergence Limited, Flipboard Magazine, \", 'loc': \"India, Baba Ka Dhaaba, Banega Swasth India, Bano India, Delhi, Desh Pradesh, New Zealand, Kurukshetra, Mahindra, Davos, Paksh Vipaksh, London, Singhu, Mumbai, Maharashtra, UK, Bengal, Tamil Nadu's, Surat, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Mukesh Ambani Security Scare: Man With Hoodie Parked Car, Letter Inside', 'name': \"Swasth, Khabar, Mamata Banerjee, Modi, Mukul Kesavan, Arvind Kejriwal, Alastair Cook, Virat Kohli, Malaika Arora, Smriti Irani, Nirav Modi, Bipasha Basu, The Girl On The Train, Parineeti Chopra's, Ravichandran Ashwin's, Rakhi Sawant's, Salman Khan, Elon, Gates, Musk, Mukesh Ambani, \", 'org': 'NDTV, BJP, AAP, BCCI, NDTV Convergence Limited, Flipboard Magazine, ', 'loc': \"India, Bengal, England, Ahmedabad, Mumbai, Maldives, Kerala, Tamil Nadu's, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'A special episode from Lavasa, catch an exclusive interview with Chris Bangle, Former Head of Design, BMW', 'name': 'Swasth, Vishnu Som, Sanket Upadhyay, Sonia Singh, Sreenivasan Jain, Modi, Vikram Chandra, Filmy Chakkar, Randeep Guleria, Khabron Ki Khabar, Des Ki Baat, Khabar Viral Hai, Afwah Banam Haqiqat, Ravish Kumar, Badi Khabar, Muqabla, Khabaron Ki Khabar, Dil Se Sewa, Chris Bangle, ', 'org': \"NDTV, NDTV 24x7, NDTV News, the Lunchtime News, the Indian Army, Max Life's, AIIMS, NDTV India, News 360, BBC Duniya, City Express, the Delhi Sikh Gurdwara Management Commitee, NDTV Profit, BMW, Oxfam, NDTV Convergence Limited, Flipboard Magazine, \", 'loc': 'India, Chhattisgarh, Delhi, Mumbai, Desh Pradesh, hindi heartland, Bollywood, Lavasa, Covid, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'CAT', 'name': 'Modi, Udhyam, Naveen Patnaik, JEE Main, CAT, ', 'org': 'NDTV, National Medical Commission, Supreme Court, Navodaya Vidyalaya Samiti Meeting, Careers360, ', 'loc': 'India, Tamil Nadu, Maharashtra, Delhi, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Opinion: The Absolutely Justifiable Renaming Of Stadium After PM Modi', 'name': 'Swasth, Corona, Erin Blakemore, Darryl Fears, Nancy Simmons, Raja Chari, Jon Vurputoor Chari, Arvind Kejriwal, Mamata Banerjee, Modi, ', 'org': 'NDTV, The Washington Post, NASA, ISRO, Agence France-Presse, the Department of Science and Technology, DST, the American Museum of Natural History, The Indian Space Research Organisation, US Air Force, IIT-Guwahati, Indian Institute of Technology, Reuters, BJP, AAP, ', 'loc': 'INDIA, Beijing, India, New Delhi, Washington, United States, China, US, Chennai, New York, Guwahati, Washington DC, Houston, Bengal, England, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Opinion: The Absolutely Justifiable Renaming Of Stadium After PM Modi', 'name': \"Swasth, Corona, Swati Mohan, Arora Akanksha, Antonio Guterres, Padma Shri Manjamma Jogati, Maya Sharma, Harish Pullanoor, Manjamma Jogathi, Manjavva Jogati, Satya Paul, Masaba Gupta's, Elon Musk, Adar Poonawalla, Rajinikanth, Uma Sudhir, Deepshikha Ghosh, Richard Verma, Ahmed Patel, Sonia Gandhi's, Tarun Gogoi, Anindita Sanyal, Soumitra Chatterjee, Monideepa Banerjie, Kamala Harris, Kamala Harris', Nandini Gupta, Meena Harris, Jack Ma, Sam Daniel Stalin, Arvind Kejriwal, Mamata Banerjee, Modi, \", 'org': \"NDTV, The National Aeronautics and Space Administration, NASA, UN, United Nations, Agence France-Presse, Serum Institute's, Serum Institute of India, The Straits Times, Mastercard, Congress, NDTV Newsdesk, Alibaba, BJP, AAP, \", 'loc': 'INDIA, Washington, Bengaluru, Karnataka, Maharashtra, Andhra Pradesh, Mumbai, New York/, Singapore, Chennai, US, India, New Delhi, Assam, America, China, Beijing, the United States of America, Tamil Nadu, England, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': '\"Is It On PM\\'s Suggestion?\" Mamata Banerjee Slams Bengal\\'s Marathon Polls', 'name': 'Swasth, Corona, Harish Pullanoor, E Sreedharan, Vaibhav Tiwari, K Surendran, Rahul Gandhi, Yogi Adityanath, Sneha Mary Koshy, Pinarayi Vijayan, Stela Dey, Uma Sudhir, Narendra Modi, Arvind Gunasekar, MK Stalin, Sam Daniel Stalin, Edappadi K Palaniswami, Sasikala, Divyanshu Dutta Roy, VK Sasikala, J Jayalalithaa, Abhishek Chakraborty, Nari Shakti\", Preeti Sudan, Arvind Kejriwal, Mamata Banerjee, ', 'org': 'NDTV, Telangana News, the Election Commission, NDTV Newsdesk, BJP, Congress, Wayanad, Rashtriya Swayamsevak Sangh, RSS, Centre, DMK, Secular Democratic Alliance, SDA, AIADMK, Assembly, Left Democratic Front, AMMK, Union, IAS, AAP, ', 'loc': \"INDIA, Andhra Pradesh, Karnataka, Kerala, Tamil Nadu, New Delhi, Puducherry, West Bengal, Assam, Tamil Nadu's, Chennai, Malappuram, Mallapuram, Uttar Pradesh, Andhra Pradesh's, Guntur, Narsaraopet, Alappuzha, Telangana, Karimnagar, Kollam, Amaravati, India, England, \", 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': '\"Is It On PM\\'s Suggestion?\" Mamata Banerjee Slams Bengal\\'s Marathon Polls', 'name': 'Swasth, Corona, Akhilesh Sharma, Sunil Prabhu, Vishnu Som, Deepshikha Ghosh, Nirav Modi, Divyanshu Dutta Roy, Nodeep Kaur, Mohammad Ghazali, Harish Pullanoor, Arvind Gunasekar, Disha Ravi, V Narayanasamy, Sam Daniel Stalin, Rahul Gandhi, Priya Ramani, Chandrashekar Srinivasan, Kiran Bedi, J Sam Daniel Stalin, Uma Sudhir, Mukesh Singh Sengar, Akshay Kumar Dongare, Anindita Sanyal, Ratnadip Choudhury, Debanish Achom, Rajnath Singh, Neeta Sharma, Roobina Mongia, Arvind Kejriwal, Mamata Banerjee, ', 'org': 'NDTV, Congress, BJP, Twitter, Defence, AAP, ', 'loc': 'INDIA, New Delhi, UK, London, Bengaluru, Puducherry, Mumbai, Assam, Sivasagar, India, China, Uttarakhand, Tapovan, England, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': 'money launder, ', 'sources': '', 'hdfcpresent': 'No'}\n","{'text': '\"Is It On PM\\'s Suggestion?\" Mamata Banerjee Slams Bengal\\'s Marathon Polls', 'name': 'Swasth, Corona, Akhilesh Sharma, Sunil Prabhu, Vishnu Som, Deepshikha Ghosh, Nirav Modi, Divyanshu Dutta Roy, Nodeep Kaur, Mohammad Ghazali, Harish Pullanoor, Arvind Gunasekar, Disha Ravi, V Narayanasamy, Sam Daniel Stalin, Rahul Gandhi, Priya Ramani, Chandrashekar Srinivasan, Kiran Bedi, J Sam Daniel Stalin, Uma Sudhir, Mukesh Singh Sengar, Akshay Kumar Dongare, Anindita Sanyal, Ratnadip Choudhury, Debanish Achom, Rajnath Singh, Neeta Sharma, Roobina Mongia, Arvind Kejriwal, Mamata Banerjee, ', 'org': 'NDTV, Congress, BJP, Twitter, Defence, AAP, ', 'loc': 'INDIA, New Delhi, UK, London, Bengaluru, Puducherry, Mumbai, Assam, Sivasagar, India, China, Uttarakhand, Tapovan, England, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': 'money launder, ', 'sources': '', 'hdfcpresent': 'No'}\n","['Swasth, Corona, Akhilesh Sharma, Sunil Prabhu, Vishnu Som, Deepshikha Ghosh, Nirav Modi, Divyanshu Dutta Roy, Nodeep Kaur, Mohammad Ghazali, Harish Pullanoor, Arvind Gunasekar, Disha Ravi, V Narayanasamy, Sam Daniel Stalin, Rahul Gandhi, Priya Ramani, Chandrashekar Srinivasan, Kiran Bedi, J Sam Daniel Stalin, Uma Sudhir, Mukesh Singh Sengar, Akshay Kumar Dongare, Anindita Sanyal, Ratnadip Choudhury, Debanish Achom, Rajnath Singh, Neeta Sharma, Roobina Mongia, Arvind Kejriwal, Mamata Banerjee,', 'NDTV, Congress, BJP, Twitter, Defence, AAP,', 'INDIA, New Delhi, UK, London, Bengaluru, Puducherry, Mumbai, Assam, Sivasagar, India, China, Uttarakhand, Tapovan, England,', datetime.datetime(2021, 2, 26, 18, 8, 44, 34218), 'money launder, ', 'No', 'https://www.ndtv.com/cheat-sheet']\n","writing csv file\n","{'text': 'Rahul Vaidya And Disha Parmar, Twinning In White, Step Out For Date Night', 'name': 'Swasth, Deepika Padukone, Ranveer Singh, Rahul Vaidya, Disha Parmar, ', 'org': 'NDTV, ', 'loc': '', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","{'text': 'Malaika Arora Turns Chef To Cook A Lavish South Indian Feast For Friends (See Pics)', 'name': \"Swasth, Virat Kohli's, Malaika Arora, \", 'org': 'NDTV, BCCI, Tesla, LG, NDTV Convergence Limited, ', 'loc': 'India, Ahmedabad, ', 'facebook_link': '', 'twitter_link': '', 'other_weblinks': '', 'image_link': '', 'keyword': '', 'sources': '', 'hdfcpresent': 'No'}\n","writing csv file\n","Crawler ran for 913.0 seconds\n","CPU times: user 2.53 s, sys: 477 ms, total: 3.01 s\n","Wall time: 15min 32s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_UEr7uv5FAoL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614364751053,"user_tz":-330,"elapsed":3414,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"3ea8146c-8909-481a-bbee-b210c4d88b27"},"source":["%cd /content/\r\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","pep.api  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U6tOkN8E8e5L"},"source":["# !rm /content/pep.api/Code/result_database/database.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wh2PcQoVLKRO"},"source":["import pandas as pd\r\n","\r\n","results = pd.read_csv('/content/pep.api/Code/result_database/database.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3yt6G9sLbjs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614364751740,"user_tz":-330,"elapsed":4039,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"09432256-007f-4874-8128-b85379dcce28"},"source":["results.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 7)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"YCNKOYV0Lb6G","colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"status":"ok","timestamp":1614364751769,"user_tz":-330,"elapsed":4057,"user":{"displayName":"Gaurav Chopra","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipwFqb9o99ceeIdkuO4dhrh_TlE4yCVopv2_xWBQ=s64","userId":"09663297046543970124"}},"outputId":"7b9f8e66-660e-4708-85bc-c06d1e63f287"},"source":["results.head().T"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Swasth, Corona, Alok Pandey, Stela Dey, Nirav Modi, Mukesh Singh Sengar, Vaibhav Tiwari, Kishori Pednekar, Mukesh Ambani's, Sunilkumar M Singh, Divyanshu Dutta Roy, Anil Deshmukh, Debanish Achom, Arvind Kejriwal, Raghav Chadha, Mamata Banerjee,</th>\n","      <td>Swasth, Corona, Akhilesh Sharma, Sunil Prabhu,...</td>\n","    </tr>\n","    <tr>\n","      <th>NDTV, Agra News, Ahmedabad News, Allahabad News, Delhi News, Ghaziabad News, Hyderabad News, Jammu News, Lucknow News, Meerut News, Mumbai News, Noida News, Surat News, Punjab National Bank, PNB, the Brihanmumbai Municipal Corporation, BMC, Delhi Jal Board, the India Meteorological Department, IMD, the Punjab State Power Corporation Limited, PSPCL, BJP, AAP,</th>\n","      <td>NDTV, Congress, BJP, Twitter, Defence, AAP,</td>\n","    </tr>\n","    <tr>\n","      <th>INDIA, Amritsar, Aurangabad, Bengaluru, Bhopal, Bhubaneshwar, Chandigarh, Chennai, Gurgaon News, Guwahati, Jaipur, Kanpur, Kolkata, Ludhiana, Muzaffarnagar, Nagpur, Patna News, Srinagar, Delhi, New Delhi, Uttar Pradesh's, Mumbai, UK, India, Covid, Maharashtra, Punjab, England,</th>\n","      <td>INDIA, New Delhi, UK, London, Bengaluru, Puduc...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-26 18:00:06.272808</th>\n","      <td>2021-02-26 18:08:44.034218</td>\n","    </tr>\n","    <tr>\n","      <th>money launder,</th>\n","      <td>money launder,</td>\n","    </tr>\n","    <tr>\n","      <th>No</th>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>https://www.ndtv.com/cities</th>\n","      <td>https://www.ndtv.com/cheat-sheet</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                    0\n","Swasth, Corona, Alok Pandey, Stela Dey, Nirav M...  Swasth, Corona, Akhilesh Sharma, Sunil Prabhu,...\n","NDTV, Agra News, Ahmedabad News, Allahabad News...        NDTV, Congress, BJP, Twitter, Defence, AAP,\n","INDIA, Amritsar, Aurangabad, Bengaluru, Bhopal,...  INDIA, New Delhi, UK, London, Bengaluru, Puduc...\n","2021-02-26 18:00:06.272808                                                 2021-02-26 18:08:44.034218\n","money launder,                                                                        money launder, \n","No                                                                                                 No\n","https://www.ndtv.com/cities                                          https://www.ndtv.com/cheat-sheet"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"jkzELapCLli-"},"source":["# Source filter\r\n","results.Source.unique().tolist() # [365:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dPmVd8DHLLh"},"source":["results.Name.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9r8r66wlHQ-9"},"source":["results.Designation.unique().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5BTdo2edZ67"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfd0U93O4xP6"},"source":[""],"execution_count":null,"outputs":[]}]}